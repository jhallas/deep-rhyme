{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect as detect_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "exclude = set(string.punctuation)\n",
    "exclude.remove(\"'\")\n",
    "exclude.remove(\".\")\n",
    "exclude.remove(\",\")\n",
    "exclude.remove(\"!\")\n",
    "exclude.remove(\"-\")\n",
    "\n",
    "special_types = exclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76898"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "paths = glob.glob(\"rap_lyrics/*/*.txt\") + glob.glob(\"rap_lyrics/*.txt\")\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_WORDS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollin hater's booii hello   hello , hello ! hello - hello gangsta gangsta 519\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_text(s):\n",
    "    out = unicode(s)\n",
    "    for st in special_types:\n",
    "        out = out.replace(st, u\" \")\n",
    "    out = re.sub(',',' , ', out)\n",
    "    \n",
    "    out = re.sub(\"\\.\",\" \\. \", out)\n",
    "    out = re.sub(\"!\",\" ! \", out)\n",
    "    out = re.sub(\"-\",\" - \", out)\n",
    "    out = re.sub(\"'+($|\\s)\",\" \", out)\n",
    "    out = re.sub(\"(^|\\s)'+\", \" \", out)\n",
    "    out = re.sub(\"(^|\\s)'+($|\\s)\", \" \", out)\n",
    "    out = re.sub(r'(.)\\1{3,}', r'\\1\\1', out)\n",
    "    out = re.sub(r'\\.',' ', out)\n",
    "#     out = re.sub(r\"\\'s\", \" \\'s\", out)\n",
    "#     out = re.sub(r\"\\'ve\", \" \\'ve\", out)\n",
    "#     out = re.sub(r\"n\\'t\", \" n\\'t\", out)\n",
    "#     out = re.sub(r\"\\'re\", \" \\'re\", out)\n",
    "#     out = re.sub(r\"\\'d\", \" \\'d\", out)\n",
    "#     out = re.sub(r\"\\'ll\", \" \\'ll\", out)\n",
    "    \n",
    "    s.encode(\"ascii\")\n",
    "    \n",
    "    arr = []\n",
    "    for c in out:\n",
    "        \n",
    "        if c in exclude:\n",
    "            arr.append(\"\")\n",
    "            continue\n",
    "        arr.append(c)\n",
    "    return \"\".join(arr).strip().lower()\n",
    "\n",
    "print(parse_text(\"\\t'rollin' hater's boooooooiiii hello.hello,hello!hello-hello gangsta' 'gangsta 519 ...''' \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76898/76898 [17:32<00:00, 73.07it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "count = 0\n",
    "skipped = 0\n",
    "\n",
    "bad_starts = set([\"chorus\", \"dj\",\"talk\", \"applause\", \"refrain\", \"intro\", \"outro\", \"bridge\", \"corrections\"])\n",
    "\n",
    "cleaned_paras = []\n",
    "\n",
    "for m in tqdm(paths):\n",
    "    l = open(m).read()\n",
    "    for para in l.split(\"\\n\\n\")[1:]:\n",
    "        lines = para.split(\"\\n\")\n",
    "        first_line = lines[0].lower()\n",
    "        \n",
    "        try:\n",
    "            para.encode(\"ascii\")\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if len(lines) < 5:\n",
    "            continue\n",
    "            \n",
    "        if np.mean([len(l) for l in lines[1:]]) < 30:\n",
    "            continue\n",
    "        \n",
    "        if any([(bs in first_line) for bs in bad_starts]):\n",
    "            skipped += 1\n",
    "            continue\n",
    "            \n",
    "        #if len(set(lines)) < len(lines):\n",
    "        #    continue\n",
    "            \n",
    "        try:\n",
    "            if detect_language(para) != \"en\":\n",
    "                continue\n",
    "#             languages = [detect_language(l) == \"en\" for l in lines[1:]]\n",
    "#             if np.mean(languages) < 0.666:\n",
    "#                 continue\n",
    "        except Exception:\n",
    "            continue\n",
    "            \n",
    "        out_lines = []\n",
    "            \n",
    "        for line in lines:\n",
    "            words = parse_text(line.lower()).split()\n",
    "            word_counter.update(words)\n",
    "            out_lines.append(\" \".join(words))\n",
    "        cleaned_paras.append(\" [lb] \".join(out_lines))\n",
    "    count += 1\n",
    "    #if count > 10000:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for mediocre rhymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "232461"
      ]
     },
     "execution_count": 746,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_paras = json.load(open('cleaned_paras.json'))\n",
    "print(len(cleaned_paras))\n",
    "\n",
    "cleaned_paras2 = []\n",
    "\n",
    "for cp in cleaned_paras:\n",
    "    lines = cp.split(' [lb] ')\n",
    "    first_line = 0\n",
    "    for l in lines:\n",
    "        if len(l.split()) < 5:\n",
    "            first_line += 1\n",
    "#         elif \"verse\" in l:\n",
    "#             first_line += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    last_line = len(lines) - 1\n",
    "    for i in range(len(lines)):\n",
    "        if len(lines[len(lines) - 1 - i].split()) < 5:\n",
    "            last_line -= 1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    if last_line - first_line < 3:\n",
    "        \n",
    "#         print(cp)\n",
    "#         print(lines, first_line, last_line)\n",
    "#         break\n",
    "        continue\n",
    "    \n",
    "    cleaned_paras2.append(' [lb] '.join(lines[first_line:last_line + 1])  + \" [vb]\")\n",
    "len(cleaned_paras2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"watch yo back motherfucker , king syze the hurricane [lb] street gentleman with a well - deserved name [lb] i'm hot i burn flame , you not you cold rain [lb] hip - hop's my first name , this rap's my last days [lb] i spit the worst pain , the pressure will burst veins [lb] my first reign way before the earth came [lb] your shit is phony , don't know me , go get your homies [lb] i'm hittin harder than jim tomey , and y'all niggaz don't know me [lb] i feel like the world owes me , gimme that [lb] i'm spittin scriptural for biblical cats , criminals with pitiful raps [lb] lyrical stats pinnacle and critical to my map [lb] check it out now nowhere i'm gonna end up , ten - hut [lb] goin long and deep , fuck drama in the streets [lb] i'm bringin karma on beats , palmin the heat [lb] only if my life's in danger [lb] come on , dog , that's a no - brainer [lb] and to this mic , man , i ain't no stranger [lb] that's why i rearrange ya , pour straight out the fuckin manger [vb]\""
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_paras2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232461\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "#print(len(cleaned_paras))\n",
    "json.dump(cleaned_paras2, open('cleaned_paras2.json', 'w'))\n",
    "cleaned_paras = json.load(open('cleaned_paras2.json'))\n",
    "print(len(cleaned_paras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"watch yo back motherfucker , king syze the hurricane [lb] street gentleman with a well - deserved name [lb] i'm hot i burn flame , you not you cold rain [lb] hip - hop's my first name , this rap's my last days [lb] i spit the worst pain , the pressure will burst veins [lb] my first reign way before the earth came [lb] your shit is phony , don't know me , go get your homies [lb] i'm hittin harder than jim tomey , and y'all niggaz don't know me [lb] i feel like the world owes me , gimme that [lb] i'm spittin scriptural for biblical cats , criminals with pitiful raps [lb] lyrical stats pinnacle and critical to my map [lb] check it out now nowhere i'm gonna end up , ten - hut [lb] goin long and deep , fuck drama in the streets [lb] i'm bringin karma on beats , palmin the heat [lb] only if my life's in danger [lb] come on , dog , that's a no - brainer [lb] and to this mic , man , i ain't no stranger [lb] that's why i rearrange ya , pour straight out the fuckin manger [vb]\""
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_paras[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0846350039951255"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ending_dict = json.load(open('ending_dict.json', 'r'))\n",
    "\n",
    "last_ending = None\n",
    "last_line = None\n",
    "\n",
    "counter = 0\n",
    "all_counter = 0\n",
    "\n",
    "for cp in cleaned_paras: #[34:35]:\n",
    "    \n",
    "    for line in cp.split(' [lb] '):\n",
    "        split = line.split()\n",
    "        if len(split) == 0:\n",
    "            continue\n",
    "        last_word = split[-1]\n",
    "        if ending_dict.get(last_word, None) is not None and \\\n",
    "            last_ending is not None and \\\n",
    "            last_word != last_ending and \\\n",
    "            ending_dict.get(last_word) == ending_dict.get(last_ending):\n",
    "                counter += 1\n",
    "#                 print(last_line)\n",
    "#                 print(line)\n",
    "#                 print(last_word)\n",
    "#                 print(last_ending)\n",
    "#                 print()\n",
    "                \n",
    "        last_ending = last_word\n",
    "        last_line = line\n",
    "        all_counter += 1\n",
    "\n",
    "counter / float(all_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "for cp in cleaned_paras:\n",
    "    word_counter.update(cp.split())\n",
    "#print(cleaned_paras[4500].replace(' [lb] ', '\\n'))\n",
    "\n",
    "rare_ranks = dict(zip([x[0] for x in word_counter.most_common()], range(len(word_counter))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_ranks['[lb]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184950"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rare_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json.dump(word_to_index, open('word_to_index_v5.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "large_embedding_matrix = np.zeros((len(rare_ranks) + 1, EMBEDDING_SIZE), dtype=np.float32)\n",
    "word_to_index = {\"[unk]\" : 0}\n",
    "large_embedding_matrix[0] = np.random.normal(size = (EMBEDDING_SIZE))\n",
    " \n",
    "bad_words = []\n",
    "\n",
    "for word, idx in rare_ranks.items():\n",
    "    if word in embedding_vectors:\n",
    "        large_embedding_matrix[idx + 1] = embedding_vectors[word]\n",
    "        word_to_index[word] = idx + 1\n",
    "    elif \"'\" in word and word.replace(\"'\", \"\") in embedding_vectors:\n",
    "        large_embedding_matrix[idx + 1] = embedding_vectors[word.replace(\"'\", \"\")]\n",
    "        word_to_index[word] = idx + 1\n",
    "    elif idx > 15000:\n",
    "        #map rare unknown words to \"[unk]\"\n",
    "        word_to_index[word] = 0\n",
    "        bad_words.append(word)\n",
    "    else:\n",
    "        large_embedding_matrix[idx + 1] = np.random.normal(size = (EMBEDDING_SIZE))\n",
    "        word_to_index[word] = idx + 1\n",
    "        bad_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 5000\n",
    "top_words = set([x[0] for x in word_counter.most_common(n)])\n",
    "\n",
    "in_vocab_scores = []\n",
    "\n",
    "for cp in cleaned_paras:\n",
    "    in_vocab = []\n",
    "    for w in cp.split():\n",
    "        if word_to_index[w] != 0 and word_to_index[w] < n:\n",
    "            in_vocab.append(True)\n",
    "        else:\n",
    "            in_vocab.append(False)\n",
    "    in_vocab_scores.append(np.mean(in_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cale's crafty , consistently creative [lb] constantly consciously communicative [lb] commanding , careful concentration [lb] causing consequential complications [lb] calamity , chaos , confusion [lb] cataclysmic , climactic conclusions [lb] cleverly contrived , classified content [lb] chronicled courtesy continuous comments [lb] conveying , crystal - clear conviction [lb] comprehensible , comfortable conditions [lb] crusading cross - country competently [lb] consulting compasses confidently [lb] castaway carrying confidential [lb] combos compiling cardinal credentials [lb] caliber , counter clockwise calendar [lb] combating carnivore , cannibal challengers [lb] arranging articulate alliances [lb] alphabetical , audible appliances [lb] above - average , atypical anomaly [lb] athletically abnormal anatomically [lb] agile , acrobatically advanced [lb] absolutely annihilating anyone against [lb] appreciated , around and abroad [lb] attentive audiences automatically applaud [lb] acknowledging , an admirable aptitude [lb] amplified appreciation , astonished attitudes [lb] all accounts ahead affirm awful aftermath [lb] among afraid attendants anxiety attacks [lb] alarming , asthmatic activation [lb] anguish , agony , aggravation [lb] accelerating avidly , abusing anatomy [lb] as antidotes are applied actively [vb]\n",
      "\n",
      "when it comes to girls ya'll [lb] i don't trust em hell nahh [lb] stay arguing and bitchin [lb] so much better in the kitchen [lb] you give em a half an inch [lb] you'll have you sittin the bench [lb] you try to throw her a bone [lb] she'll try to move in your home [lb] ain't nothing good bout her but the d cups [lb] that's exactly why i keep the toilet seat up [vb]\n"
     ]
    }
   ],
   "source": [
    "sorted_ranks = np.argsort(in_vocab_scores)\n",
    "\n",
    "print(cleaned_paras[sorted_ranks[10]])\n",
    "print()\n",
    "print(cleaned_paras[sorted_ranks[-40000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97444177256917341"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(in_vocab_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233315"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that time when i saw ya i thought , wow , so [lb] check out the skirt on that , now straight to the bar - <<tequila>> , lemon , salt [lb] i give her the all clear , letting her know green light , letting her go [lb] dropped her from a mile away , thought to myself , why not give it a go [vb] "
     ]
    }
   ],
   "source": [
    "for w in cleaned_paras[sorted_ranks[-20000]].split():\n",
    "    if word_to_index[w] != 0 and word_to_index[w] < 5000:\n",
    "        out = w\n",
    "    else:\n",
    "        out = \"<<%s>>\"%w\n",
    "    print(out, end = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42389926"
      ]
     },
     "execution_count": 751,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_lines = []\n",
    "\n",
    "words = []\n",
    "\n",
    "for r in np.random.permutation(sorted_ranks[-70000:]):\n",
    "    cp = cleaned_paras[r]\n",
    "    for w in cp.split():\n",
    "        words.append(w)\n",
    "#         if w in top_words:\n",
    "#             words.append(w)\n",
    "#         else:\n",
    "#             words.append(\"[UNK]\")\n",
    "            \n",
    "    #words.append('[lb]')\n",
    "            \n",
    "text = \" \".join(words)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verse 1 true - asia [lb] this be that brook - nam style to the 22nd psalm [lb] the walk has been long but still remain strong [lb] trials and tribulation try to leave my brain scattered [lb] i've been bruised and battered , abused by grammar [lb] still don't matter , hands clapped , tears down my cheek [lb] lord i feel weak but still it's you i seek [lb] it's crazy , sometimes i get the strength of the navy [lb] other times i feel like curling up like a baby [lb] i crack open the book the bread i take daily [lb] like god fed elijah , christ will never fail me [lb] exhale relief , the holy spirit never fails to leak [lb] all glory , all hail the chief [lb] king priest , pray and never let the spirit cease [lb] there's drama all around me but still i feel at peace [lb] at least i died to the flesh living it right [lb] living this life , because i'm christ infinite wife [vb] [vb]\n"
     ]
    }
   ],
   "source": [
    "for cp in cleaned_paras:\n",
    "    if 'verse 1' in cp:\n",
    "        print(cp)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('rap_lyrics_5000.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 50149776\n"
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open('rap_lyrics_5000.txt').read().lower()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ng shit with that funky bitch up in that fuddruckers [lb] you best to be a mud ducker , i'm a thug bucker [lb] and i got one specially designed for all you motherfuckers [lb] we love ruckus , wanna shuck and jive [lb] but when i came through with that four to the fucking five [lb] niggas duck and dive [lb] what a fucking liar [lb] bitch ain't no time to get flossed up [lb] i'm sauced up you said it cost what woo - d [vb] i specialize in snatching vertebrae break your anatomy down to a , call [lb] me atomic sensai aka b j mckay , and his best friend bear will hit you [lb] with shirley murdock a\""
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[1000:1600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 20)"
      ]
     },
     "execution_count": 693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = dict([(v,k) for k,v in word_to_index.items()])\n",
    "\n",
    "UNK_INDEX = word_to_index[\"[unk]\"]\n",
    "LB_INDEX = word_to_index[\"[lb]\"]\n",
    "VB_INDEX = word_to_index[\"[vb]\"]\n",
    "UNK_INDEX, LB_INDEX, VB_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 10480749\n"
     ]
    }
   ],
   "source": [
    "text_indexes = [word_to_index[w] for w in text.split()]\n",
    "text_indexes = list(reversed(text_indexes))\n",
    "len(text_indexes)\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "VOCAB_SIZE = 5000\n",
    "MAX_WORDS = 16\n",
    "#maxlen = 64\n",
    "step = 1\n",
    "sentences = []\n",
    "next_words = []\n",
    "for i in range(0, len(text_indexes) - MAX_WORDS, step):\n",
    "    next_text = text_indexes[i: i + MAX_WORDS]\n",
    "    next_word = text_indexes[i + MAX_WORDS]\n",
    "    if next_word == UNK_INDEX or next_word == VB_INDEX or next_word >= VOCAB_SIZE:\n",
    "        pass\n",
    "    else:\n",
    "        sentences.append(next_text)\n",
    "        next_words.append(next_word)\n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10480749, 16), (10480749, 1))"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(sentences)\n",
    "\n",
    "y = np.expand_dims(next_words, -1)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 128\n",
    "# NUM_STEPS = 35\n",
    "# MAX_RANK = 5000\n",
    "# MAX_GRAD_NORM = 5.\n",
    "\n",
    "# class BatchIterator:\n",
    "    \n",
    "#     def __init__(self, sentences, next_words, batch_size=BATCH_SIZE, num_steps=MAX_WORDS, reshuffle=False):\n",
    "#         self.sentences = sentences\n",
    "#         self.next_words = next_words\n",
    "#         self.batch_size = batch_size\n",
    "#         self.num_steps = num_steps\n",
    "#         self.reshuffle = reshuffle\n",
    "#         self.index = 0\n",
    "        \n",
    "#         self.X = np.array(sentences)\n",
    "#         self.y = np.array(next_words)\n",
    "        \n",
    "#         self.len_text = len(sentences)\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "    \n",
    "#     def reset_words(self):\n",
    "#         print(\"resetting iterator\")\n",
    "#         if self.reshuffle:\n",
    "#             #TODO : do something here\n",
    "#             pass\n",
    "#         self.index = 0\n",
    "        \n",
    "#     def next(self):\n",
    "#         if (self.index + self.batch_size) * NUM_STEPS + 1 >= self.len_text:\n",
    "#             self.reset_words()\n",
    "            \n",
    "#         x_ = self.X[(self.index * self.batch_size) : (self.index + 1) * self.batch_size]\n",
    "        \n",
    "#         y_ = np.zeros((self.batch_size, 1000), dtype=np.bool)\n",
    "        \n",
    "#         for i, y in enumerate(self.y[(self.index * self.batch_size) : (self.index + 1) * self.batch_size]):\n",
    "#             y_[i, y] = 1\n",
    "        \n",
    "#         self.index += 1   \n",
    "#         return x_ , y_\n",
    "\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# train_idxs, val_idxs = train_test_split(range(len(sentences)), test_size=0.33, random_state=42)\n",
    "# train_iter = BatchIterator([sentences[i] for i in train_idxs], [next_words[i] for i in train_idxs])\n",
    "# val_iter = BatchIterator([sentences[i] for i in val_idxs], [next_words[i] for i in val_idxs])\n",
    "\n",
    "# x, y = train_iter.next()\n",
    "# x.shape, y.shape\n",
    "\n",
    "# x, y = train_iter.next()\n",
    "# s = ' '.join([index_to_word[idx] for idx in x[0]])\n",
    "# print(s)\n",
    "# print(index_to_word[y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50 #100, 200, 300\n",
    "\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_SIZE), dtype=np.float32)\n",
    "embedding_vectors = {}\n",
    "embedding_raw = open('glove.twitter.27B.%id.txt'% EMBEDDING_SIZE).read()\n",
    "#embedding_raw = open('glove.6B.%id.txt'% EMBEDDING_SIZE).read()\n",
    "for line in embedding_raw.split('\\n')[:-1]:\n",
    "    split = line.split()\n",
    "    word = split[0]\n",
    "    embedding = np.array([float(s) for s in split[1:]])\n",
    "    embedding_vectors[word] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.9% of words have GloVe embeddings\n"
     ]
    }
   ],
   "source": [
    "words_in_embed_dict = sum([word in embedding_vectors for word in word_to_index])\n",
    "\n",
    "bad_words = []\n",
    "\n",
    "for word, idx in word_to_index.items():\n",
    "    if word in embedding_vectors:\n",
    "        embedding_matrix[idx] = embedding_vectors[word]\n",
    "    elif \"'\" in word and word.replace(\"'\", \"\") in embedding_vectors:\n",
    "        embedding_matrix[idx] = embedding_vectors[word.replace(\"'\", \"\")]\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(size = (EMBEDDING_SIZE))\n",
    "        bad_words.append(word)\n",
    "        \n",
    "print(\"%.1f%% of words have GloVe embeddings\"%(100 -100 * float(len(bad_words)) / len(word_to_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "saved_weights = K.eval(e.weights[0])\n",
    "np.save(open('large_weights.np', 'w'), K.eval(e.weights[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.objectives import sparse_categorical_crossentropy\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                  patience=1, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_UNITS = 256\n",
    "HIDDEN_UNITS2 = 256\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "#embed_matrix = large_embedding_matrix\n",
    "embed_matrix = saved_weights\n",
    "\n",
    "dropout_frac = 0.01\n",
    "\n",
    "e = Embedding(len(embed_matrix), EMBEDDING_SIZE, input_length=MAX_WORDS, weights=[embed_matrix], trainable=False)\n",
    "model.add(e)\n",
    "\n",
    "model.add(LSTM(HIDDEN_UNITS, input_shape=(MAX_WORDS, EMBEDDING_SIZE), return_sequences=True, dropout_W=dropout_frac))\n",
    "model.add(LSTM(HIDDEN_UNITS2, input_shape=(MAX_WORDS, HIDDEN_UNITS), dropout_W=dropout_frac)) \n",
    "\n",
    "model.add(Dense(VOCAB_SIZE))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "\n",
    "# doesn't help\n",
    "#optimizer = Adam()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e.trainable = True\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[54, 1182, 29, 35, 1, 3098, 12, 15, 78, 234, 3, 30, 135, 31, 50, 1]"
      ]
     },
     "execution_count": 765,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "9432674/9432674 [==============================] - 1260s - loss: 4.5982 - val_loss: 4.2837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:17<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "9432674/9432674 [==============================] - 1263s - loss: 4.1956 - val_loss: 4.1984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [02:17<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "9432674/9432674 [==============================] - 1264s - loss: 4.1249 - val_loss: 4.1677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [02:18<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "9432674/9432674 [==============================] - 1265s - loss: 4.0893 - val_loss: 4.1524"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [02:18<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "9432674/9432674 [==============================] - 1266s - loss: 4.0675 - val_loss: 4.1384"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [02:18<00:00,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train on 9432674 samples, validate on 1048075 samples\n",
      "Epoch 1/1\n",
      "1490000/9432674 [===>..........................] - ETA: 1052s - loss: 4.0310\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "\n",
    "try:\n",
    "    # N.B validation split is not random, so it's ok to call fit more than once\n",
    "    for i in range(35):\n",
    "        \n",
    "        model.fit(X, y, batch_size=10000, validation_split=0.1, nb_epoch=1, callbacks=[reduce_lr])\n",
    "        \n",
    "        try:\n",
    "            text = generate_text(sentence)\n",
    "            f = open('output_text_%i'%i, 'w')\n",
    "            f.write(text)\n",
    "            f.close()\n",
    "        except Exception:\n",
    "            print('write failed')\n",
    "            \n",
    "#         if i%5 == 0:\n",
    "#             filepath = \"dprime_v7_%i.keras\" %i\n",
    "#             model.save(filepath)\n",
    "#             lr = float(K.get_value(optimizer.lr))\n",
    "#             new_lr = lr * 0.1\n",
    "#             K.set_value(optimizer.lr, new_lr)\n",
    "            \n",
    "        \n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print()\n",
    "    print(\"KeyboardInterrupt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009999999310821295"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "lr = float(K.get_value(optimizer.lr))\n",
    "new_lr = lr * 0.1\n",
    "K.set_value(optimizer.lr, new_lr)\n",
    "float(K.get_value(optimizer.lr))\n",
    "#optimizer.lr.assign(10000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = np.array(sentences)\n",
    "\n",
    "# y = np.zeros((len(next_words), VOCAB_SIZE), dtype=bool)\n",
    "# for i, y_ in enumerate(next_words):\n",
    "#     y[i, y_] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"dprime_v6.keras\"\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(preds):\n",
    "    return sum([- p * np.log(p) for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"for down still i'm and [lb] you like just , homey , crib my and kids\"\n",
      "kids and my crib , homey , just like you [lb] and i'm still down forfor my\n",
      "do this shit for me , i don't know what to do\n",
      "i'll die for you , my nigga , i don't know what to do\n",
      "just to ride for you , for you , with , me for you\n",
      "i run up , and i ride for you\n",
      "and try to disrespect and i'll die for you\n",
      "i stand up with you\n",
      "i wanna be with you\n",
      "i don't need somebody to talk to\n",
      "i'm coming home to you\n",
      "that's what i've been through\n",
      "i'ma spend it all on you\n",
      "you comin from me coming home to you\n",
      "but you know i miss you too\n",
      "you believe it when you look at me\n",
      "\n",
      "\n",
      "----- diversity: 0.6\n",
      "----- Generating with seed: \"for down still i'm and [lb] you like just , homey , crib my and kids\"\n",
      "kids and my crib , homey , just like you [lb] and i'm still down formy\n",
      "i'll have you , i'll be here for you\n",
      "i'ma take you down , i break it down for you\n",
      "i see you lookin at me , runnin to you\n",
      "give it to me , give it to me\n",
      "give it to me , give it to me\n",
      "give it to me\n",
      "give it to me , give it to me\n",
      "as far as you want it so give it to me\n",
      "give it to me\n",
      "would you have love for me\n",
      "let me let me know if you wasn't there for me\n",
      "you got to believe me i take it to the , take it to the , take it to the\n",
      "take it after me , homie , let the bullet in the blood ,\n",
      "come on , come on , come on , come on ,\n",
      "\n",
      "\n",
      "----- diversity: 0.7\n",
      "----- Generating with seed: \"for down still i'm and [lb] you like just , homey , crib my and kids\"\n",
      "kids and my crib , homey , just like you [lb] and i'm still down formy\n",
      "if you find me , until you got to get me right near you\n",
      "it's me , i'm not gon take it down for me you\n",
      "it's good to be with you , when i come with you\n",
      "i'll do something good for you , i'll do you\n",
      "do what you do , fuck you up , like i do , like i do\n",
      "bitch\n",
      "i know you a bitch , and i'm a hoe , hoe\n",
      "forget it , bitch is here than real\n",
      "whats shit , now i'm with it\n",
      "it was like this , i had to do it , nigga\n",
      "when i was rich , i never had nothing like this\n",
      "they talk about what they say , what !\n",
      "i like it like that ! like fuck that !\n",
      "and they know !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_index = np.random.randint(1000000)\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "for diversity in [ 0.5, 0.6, 0.7]: #, 1.0, 2.0]: #, 1.0, 1.2]:\n",
    "    print()\n",
    "    print('----- diversity:', diversity)\n",
    "\n",
    "    generated = []\n",
    "    sentence = text_indexes[start_index: start_index + MAX_WORDS]\n",
    "    generated += sentence\n",
    "    sentence_string = ' '.join([index_to_word[idx] for idx in sentence])\n",
    "    \n",
    "    print('----- Generating with seed: \"' + sentence_string + '\"')\n",
    "    generated_string = ' '.join(reversed([index_to_word[idx] for idx in generated]))\n",
    "    sys.stdout.write(generated_string)\n",
    "    \n",
    "    next_sentence = []\n",
    "    perplexities = []\n",
    "    \n",
    "    should_rhyme = False\n",
    "    \n",
    "    for i in range(15):\n",
    "        while(True):\n",
    "            x = np.array(sentence).reshape((1, MAX_WORDS))\n",
    "            #for t, char in enumerate(sentence):\n",
    "            #    x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "\n",
    "            next_index = sample(preds, diversity)\n",
    "            plx = preds[next_index]\n",
    "\n",
    "            generated += [next_index]\n",
    "\n",
    "            sentence = sentence[1:] + [next_index]\n",
    "            next_word = index_to_word[next_index]\n",
    "            if next_word == '[lb]':\n",
    "    #             last_word = get_next_rhyme(next_sentence[0], 0.5, rhymes = should_rhyme)\n",
    "    #             should_rhyme = not should_rhyme\n",
    "    #             sys.stdout.write(' '.join(reversed(next_sentence)) + '\\n')\n",
    "\n",
    "    #             next_sentence = [last_word]\n",
    "    #             generated += [word_to_index[last_word]]\n",
    "                sys.stdout.write(' '.join(reversed(next_sentence)) + '\\n')\n",
    "                #sys.stdout.write(' '.join(reversed(perplexities)) + '\\n')\n",
    "                next_sentence = []\n",
    "                perplexities = []\n",
    "                break\n",
    "            else:\n",
    "                next_sentence.append(next_word)\n",
    "                #next_sentence.append(next_word.ljust(7))\n",
    "                #perplexities.append((\"%.4f\"%plx).ljust(7))\n",
    "                pass\n",
    "                ##sys.stdout.write(next_word + ' ')\n",
    "            sys.stdout.flush()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEAM SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def beam_search(prefix, B = 20, search_size = 20, \n",
    "                min_length = 10, seed = None, \n",
    "                T = 1., branch_factor=10,\n",
    "                forbidden_words = {}):\n",
    "    if seed is None:\n",
    "        start_hypotheses = [[]]\n",
    "    else:\n",
    "        start_hypotheses = [[seed]]\n",
    "    start_log_probs = [0.]\n",
    "    next_hypotheses, next_log_probs = extend_beam(prefix, start_hypotheses, \n",
    "                                                  start_log_probs, B = B, \n",
    "                                                  branch_factor=branch_factor,\n",
    "                                                  forbidden_words=forbidden_words)\n",
    "    #print(zip(hypotheses, log_probs))\n",
    "    \n",
    "    finished_hypotheses = []\n",
    "    finished_log_probs = []\n",
    "    \n",
    "    for i in range(search_size):\n",
    "        #print(len(next_hypotheses))\n",
    "        #print(len(finished_hypotheses))\n",
    "        ext_hypotheses, ext_lps = extend_beam(prefix, next_hypotheses, \n",
    "                                              next_log_probs, \n",
    "                                              min_length=min_length, \n",
    "                                              B = B, \n",
    "                                              branch_factor=branch_factor,\n",
    "                                              forbidden_words=forbidden_words)\n",
    "        next_hypotheses = []\n",
    "        next_log_probs = []\n",
    "        for h, p in zip(ext_hypotheses, ext_lps):\n",
    "            \n",
    "            if LB_INDEX in h:\n",
    "                finished_hypotheses.append(h)\n",
    "                finished_log_probs.append(p)\n",
    "            else:\n",
    "                next_hypotheses.append(h)\n",
    "                next_log_probs.append(p)\n",
    "        if len(next_hypotheses) == 0:\n",
    "            #print(\"breaking\")\n",
    "            break\n",
    "                    \n",
    "    return finished_hypotheses, finished_log_probs\n",
    "\n",
    "def adjust_preds(preds, temperature = 1.):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    return preds\n",
    "    \n",
    "def extend_beam(prefix, hypotheses, log_probs, \n",
    "                B = None, min_length=10, \n",
    "                T = 1., branch_factor=10,\n",
    "                forbidden_words = {}):\n",
    "    \n",
    "    if B is None:\n",
    "        B = len(hypotheses)\n",
    "    x = []\n",
    "    for h in hypotheses:\n",
    "        x.append((prefix + h)[ -MAX_WORDS:])\n",
    "    x = np.array(x)\n",
    "    preds_all = model.predict(x, verbose=0)\n",
    "    \n",
    "    new_hypotheses = []\n",
    "    new_log_probs =  []\n",
    "    \n",
    "    for h, lp, preds in zip(hypotheses, log_probs, preds_all):\n",
    "        preds = adjust_preds(preds, temperature=T)\n",
    "        h_set = set(h)\n",
    "        p_set = set(prefix)\n",
    "        for idx in np.argsort(preds)[::-1][:branch_factor]:\n",
    "            p = preds[idx]\n",
    "            \n",
    "            if idx in h_set:\n",
    "                continue\n",
    "            if idx != LB_INDEX and idx in prefix:\n",
    "                continue\n",
    "            if idx == LB_INDEX and len(h) < min_length:\n",
    "                continue\n",
    "            if idx in forbidden_words:\n",
    "                continue\n",
    "            new_hypotheses.append(h + [idx])\n",
    "            new_log_probs.append(lp + np.log(p))\n",
    "            \n",
    "    sorted_indexes = np.argsort(new_log_probs)[::-1][:B]\n",
    "    best_hypotheses = [new_hypotheses[i] for i in sorted_indexes]\n",
    "    best_probs = [new_log_probs[i] for i in sorted_indexes]\n",
    "    \n",
    "    return best_hypotheses, best_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_log_probs(log_probs,T=1.):\n",
    "    max_ = max(log_probs)\n",
    "    scale_up = [np.exp(x + max_) for x in log_probs]\n",
    "    sum_ = sum(scale_up)\n",
    "    return sample([x/ sum_ for x in scale_up], temperature=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finished_hypotheses, finished_log_probs = beam_search(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[lb] and we gotta get up on the dance floor'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([index_to_word[i] for i in reversed(finished_hypotheses[sample_log_probs(finished_log_probs)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[lb] we can do it tonight , come on [lb] come on , come on ,'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_sentence(sentence):\n",
    "    return \" \".join([index_to_word[i] for i in reversed(sentence)])\n",
    "\n",
    "convert_sentence(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1750"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_dict2 = {}\n",
    "for k, v in rhyme_dict.items():\n",
    "    if rare_ranks[k] > 500 and word_to_index[k] < VOCAB_SIZE:\n",
    "        rare = [x for x in v if word_to_index[x] > 500 and word_to_index[x] < VOCAB_SIZE]\n",
    "        rhyme_dict2[k] = rare\n",
    "        \n",
    "bad_keys = [k for k, v in rhyme_dict2.items() if len(v) < 5 or word_to_index[x] >= VOCAB_SIZE]\n",
    "for k in bad_keys:\n",
    "    del rhyme_dict2[k]\n",
    "len(rhyme_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'forget',\n",
       " [u'regret',\n",
       "  u'jet',\n",
       "  u'upset',\n",
       "  u'vet',\n",
       "  u'bed',\n",
       "  u'met',\n",
       "  u'sweat',\n",
       "  u'threat',\n",
       "  u'wet',\n",
       "  u'debt',\n",
       "  u'yet',\n",
       "  u'bet'])"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhyme_dict2.items()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'sunday' in rhyme_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "    \n",
    "def generate_text(sentence):\n",
    "    \n",
    "    used_endings = set()\n",
    "\n",
    "    seed = np.random.choice(rhyme_dict.keys())\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    forbidden_words = set()\n",
    "    for w in ['baby', 'love', \"she\", \"she'll\", \"she's\", \n",
    "              \"chick\", \"chicks\", \"girl\", \"girls\", \"cake\", \"cry\", \"bricks\"]:\n",
    "        forbidden_words.add(word_to_index[w])\n",
    "\n",
    "    for i in tqdm(range(50)):\n",
    "        if i == 0:\n",
    "            end_word = seed\n",
    "        else:\n",
    "            end_word = lines[-1].split()[-1]\n",
    "        used_endings.add(end_word)\n",
    "        end = ending_dict[end_word]\n",
    "\n",
    "        if i % 2 == 0:\n",
    "\n",
    "            good_indices = [word_to_index[w] for w in rhyme_dict2.keys() if w not in used_endings.union(forbidden_words)]\n",
    "            #good_indices = [word_to_index[w] for w in seed_list if w not in used_endings]\n",
    "        else:\n",
    "            #end_end_word = lines[-2].split()[-1]\n",
    "            good_indices = [word_to_index[w] for w in rhyme_dict2[end_word] if w not in used_endings.union(forbidden_words)]\n",
    "\n",
    "        x = np.array(sentence).reshape((1, MAX_WORDS))\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        ps = [preds[idx] for idx in good_indices]\n",
    "\n",
    "        seed = good_indices[sample(ps)]\n",
    "\n",
    "        #line_len = np.random.normal(loc = mu, scale = 1.)\n",
    "        line_len = 10.\n",
    "\n",
    "        finished_hypotheses, finished_log_probs = beam_search(sentence, min_length=line_len, \n",
    "                                                              seed=seed, \n",
    "                                                              T = 1., \n",
    "                                                              B=128,\n",
    "                                                              branch_factor=10,\n",
    "                                                              forbidden_words=forbidden_words)\n",
    "        #for h, p in zip(finished_hypotheses, finished_log_probs):\n",
    "        #    print(p, convert_sentence(h[:-1]))\n",
    "        chosen_hypothesis = finished_hypotheses[sample_log_probs(finished_log_probs, T=1.)]\n",
    "        line_string = convert_sentence(chosen_hypothesis[:-1])\n",
    "        lines.append(line_string)\n",
    "        #print(line_string)\n",
    "        #print(line_string in text)\n",
    "        sentence = (sentence + chosen_hypothesis)[-MAX_WORDS:]\n",
    "\n",
    "    out = \"\\n\".join(reversed(lines))\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [02:16<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cause i'm the type of nigga that ain't got no dough\n",
      "i don't give a fuck , it's time to jump\n",
      "then we gon get up in this bitch and duck\n",
      "all you thirsty ass bitches , from rags to riches\n",
      "holla at a nigga with the ice on my wrist\n",
      "i don't come back , you can call me jack\n",
      "i'm just tryin to get up out of them bars\n",
      "no matter what's the difference between me and you guys\n",
      "live my life , all i need is a dream\n",
      "but you'll never be the only one that can speak\n",
      "if you try to get caught up in a killin\n",
      "shit , i don't know what them niggas be thinkin\n",
      "tell me why the fuck do you think i'm dealin\n",
      "there ain't no time to get up out this rat\n",
      "but i don't really give a fuck about that law\n",
      "now tell me , this is the end of these songs\n",
      "open up my eyes when i look at that sky\n",
      "you got a nigga like me , rest in peace\n",
      "all the bitch - ass niggas tryin to get paid\n",
      "they don't wanna fuck with me , let's take flight\n",
      "you know we can do it from the west coast\n",
      "i gots to put your hands down on tha floor\n",
      "don't make me throw that ass up at the bar\n",
      "fuck a bitch , i'm bout to get some sticks\n",
      "so if you see me at the top of my stroke\n",
      "and i know , god damn it feels good to be ok\n",
      "now let me tell you what's up with that stuff\n",
      "who in the fuck am i supposed to be on top of my plane\n",
      "oh , let me see you paint a perfect picture\n",
      "look into your eyes and wonder why the truth hurts\n",
      "it feels like i ain't got no time to cry\n",
      "you see in my eyes , look at the smile\n",
      "please don't make me have to sit up on your wall\n",
      "and i remember back in the day that you cried\n",
      "so much more than just a little bit of mess\n",
      "all my life ain't no need for me to crawl\n",
      "but when i wake up , i'm so tired of the lies\n",
      "look it in my eyes and give me a prayer\n",
      "you can tell by the way that i was playing\n",
      "but now i'm back up in a rear - view\n",
      "and try to act like i ain't seen it yet\n",
      "when you see me get the fuck up off of my nuts\n",
      "all these punk - ass niggas is scared to bite\n",
      "so if a nigga don't wanna fuck with me tonight\n",
      "yeah , i got it in the back of my lac\n",
      "and i'm ready to rock a party til it's dark\n",
      "when you see me at the top of them jeans\n",
      "stick my dick in yo ass like it's all gravy\n",
      "throw it up , give me head to the tone\n",
      "and you know i got a grip on my chrome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and it really don't matter what these niggas say nah\n",
      "ain't no limit soldiers , i'm ready to die for ya\n",
      "gettin caught up in the parkin and m o b\n",
      "y'all don't wanna roll with me , a - t\n",
      "yeah i said it feels good to be my baby\n",
      "caught up in the game , i'm low - key\n",
      "they don't do me more than a no limit party\n",
      "that's how it supposed to be , d p g\n",
      "where the fuck am i tryna get me some money\n",
      "cuz i'm a real nigga , this shit is funny\n",
      "and it ain't got no time for me to quit\n",
      "but i aint gotta worry about none of that shit\n",
      "i've learned too much in my life , this kid\n",
      "and there's a lot of things to do with it\n",
      "i ain't never gonna be all alone on this one\n",
      "let's party till the day that we die , son\n",
      "tell me how does it feel like it's my turn\n",
      "cause all i need is much more that we can learn\n",
      "come up and let me take a look at the light\n",
      "if there ain't no way that it can be alright\n",
      "i know , how we used to party all night\n",
      "now look at the same time that life was right\n",
      "so give me up for , just to get by\n",
      "i can't do it when they look at my sky\n",
      "but no matter how many niggas ain't scared to die\n",
      "pull up in the sky , with my hands high\n",
      "when i put it down for them niggas all around\n",
      "ya'll niggaz don't really wanna fuck with this dogg pound\n",
      "just a nigga like me , that's the way it's going down\n",
      "and i know it really don't matter if i'm underground\n",
      "turn that fire on the water won't let me go\n",
      "at all y'all niggas tryin to make my cash flow\n",
      "i've got a lot of things that they don't know\n",
      "and we can get what i have to do so\n",
      "i'm gonna be the only one you've never seen before\n",
      "when a whole lot of people wanna go to war\n",
      "and i don't even know what you've been waiting for\n",
      "one more time , when it comes to those stars\n",
      "i'm sick of all the things that we can see\n",
      "sometimes i don't want to mention my name is history\n",
      "cause there's no way they can take it from me\n",
      "but it's so hard for me to be a fantasy\n"
     ]
    }
   ],
   "source": [
    "for line in reversed(lines):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rare_ranks = dict(zip([x[0] for x in word_counter.most_common()], range(len(word_counter))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['porn',\n",
       " 'hardcore',\n",
       " 'pussy',\n",
       " 'sexy',\n",
       " 'teen',\n",
       " 'bad',\n",
       " 'chicks',\n",
       " 'body',\n",
       " 'girls',\n",
       " 'horny',\n",
       " 'girl',\n",
       " 'women',\n",
       " 'freaks',\n",
       " 'dope',\n",
       " 'freak',\n",
       " 'lover']"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "vector = saved_weights[word_to_index['sex']]\n",
    "cosines = [cosine(v, vector) for v in saved_weights]\n",
    "seed_list = [index_to_word[i] for i in np.argsort(cosines)[1:40]]\n",
    "seed_list = [s for s in seed_list if s in rhyme_dict]\n",
    "#seed_list = [s for s in seed_list if rare_ranks[s] > 500]\n",
    "seed_list = seed_list[:16]\n",
    "seed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"drinking too much\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end = ending_dict[lines[-1].split()[-1]] \n",
    "\n",
    "good_indices = [word_to_index[w] for w in ending_to_word[tuple(end)]]\n",
    "\n",
    "x = np.array(sentence).reshape((1, MAX_WORDS))\n",
    "preds = model.predict(x, verbose=0)[0]\n",
    "ps = [preds[idx] for idx in good_indices]\n",
    "index_to_word[good_indices[sample(ps)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2701"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rhyme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "line_lens = [len(line.split()) for line in text.split(' [lb] ')]\n",
    "mu = np.mean(line_lens)\n",
    "sigma = np.std(line_lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('common_words_5000.txt', 'w') as f:\n",
    "    for w in word_to_index.keys():\n",
    "        if '[' not in w:\n",
    "            f.write(\"%s\\n\"%w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "ending_dict = json.load(open('ending_dict.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "ending_to_word = defaultdict(list)\n",
    "for w, l in ending_dict.items():\n",
    "    ending_to_word[tuple(l)].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"stops\" < \"stop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_pair = Counter()\n",
    "\n",
    "for cp in cleaned_paras:\n",
    "    lines = cp.split(' [lb] ')\n",
    "    for line1, line2 in zip(lines[:-1], lines[1:]):\n",
    "        try:\n",
    "            word1 = line1.split()[-1]\n",
    "            word2 = line2.split()[-1]\n",
    "            if word1 == '!':\n",
    "                word1 = line1.split()[-2]\n",
    "            \n",
    "            if word2 == '!':\n",
    "                word2 = line2.split()[-2]\n",
    "                \n",
    "            word_pair[tuple(sorted([word1, word2]))] += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'AE', u'SZ']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ending_dict['has']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rhyme_dict = defaultdict(set)\n",
    "\n",
    "for pair, ct in word_pair.items():\n",
    "    if ct < 3:\n",
    "        continue\n",
    "    w1, w2 = pair\n",
    "    \n",
    "    if w1 in w2 or w2 in w1:\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        ending1 = ending_dict[w1]\n",
    "        ending2 = ending_dict[w2]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if ending1 == ending2 and w1 != w2:\n",
    "            rhyme_dict[w1].add(w2)\n",
    "            rhyme_dict[w2].add(w1)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_keys = [k for k, v in rhyme_dict.items() if len(v) < 5]\n",
    "for k in bad_keys:\n",
    "    del rhyme_dict[k]\n",
    "min([len(v) for k, v in rhyme_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "word_pair_dict = defaultdict(list)\n",
    "rhyme_pair_dict = defaultdict(list)\n",
    "d1 = defaultdict(list)\n",
    "\n",
    "for fn , d in [('word_pairs.txt', word_pair_dict), ('rhymes.txt', rhyme_pair_dict)]:\n",
    "\n",
    "    for line in open(fn).read().split('\\n')[:-1]:\n",
    "        w0, w1, n_str = line.split()\n",
    "        n = int(n_str)\n",
    "        d[w1].append((w0, n))\n",
    "        \n",
    "    items = tuple(d.items())\n",
    "    \n",
    "    for w, l in items:\n",
    "        total = sum([x[1] for x in l])\n",
    "        d[w] = [(w2, float(n) / total) for w2, n in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chance', 0.7515527950310559), ('man', 0.2484472049689441)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rhyme_pair_dict['dance'] = []\n",
    "rhyme_pair_dict['dance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foul', [('now', 0.5581395348837209), ('style', 0.4418604651162791)]),\n",
       " ('four',\n",
       "  [('for', 0.20422535211267606),\n",
       "   ('more', 0.19718309859154928),\n",
       "   ('door', 0.18309859154929578),\n",
       "   ('three', 0.14788732394366197),\n",
       "   ('raw', 0.13380281690140844),\n",
       "   ('floor', 0.13380281690140844)]),\n",
       " ('sleep',\n",
       "  [('deep', 0.21291448516579406),\n",
       "   ('me', 0.13961605584642234),\n",
       "   ('streets', 0.08027923211169284),\n",
       "   ('eat', 0.07853403141361257),\n",
       "   ('creep', 0.07678883071553229),\n",
       "   ('street', 0.06457242582897033),\n",
       "   ('week', 0.059336823734729496),\n",
       "   ('heat', 0.059336823734729496),\n",
       "   ('keep', 0.04537521815008726),\n",
       "   ('feet', 0.04363001745200698),\n",
       "   ('weak', 0.04013961605584642),\n",
       "   ('beat', 0.03664921465968586),\n",
       "   ('it', 0.03315881326352531),\n",
       "   ('beef', 0.029668411867364748)]),\n",
       " ('hate',\n",
       "  [('straight', 0.19617224880382775),\n",
       "   ('fake', 0.13875598086124402),\n",
       "   ('state', 0.11004784688995216),\n",
       "   ('weight', 0.11004784688995216),\n",
       "   ('me', 0.09569377990430622),\n",
       "   ('date', 0.09569377990430622),\n",
       "   ('fate', 0.09090909090909091),\n",
       "   ('face', 0.08133971291866028),\n",
       "   ('make', 0.08133971291866028)]),\n",
       " ('drinkin', [('thinkin', 1.0)]),\n",
       " ('under',\n",
       "  [('wonder', 0.5862068965517241),\n",
       "   ('number', 0.23275862068965517),\n",
       "   ('jungle', 0.1810344827586207)]),\n",
       " ('lord', [('hard', 1.0)]),\n",
       " ('pride',\n",
       "  [('side', 0.37037037037037035),\n",
       "   ('ride', 0.3425925925925926),\n",
       "   ('inside', 0.28703703703703703)]),\n",
       " ('worth',\n",
       "  [('earth', 0.6594202898550725),\n",
       "   ('birth', 0.1956521739130435),\n",
       "   ('work', 0.14492753623188406)]),\n",
       " ('callin', [('ballin', 0.7428571428571429), ('fallin', 0.2571428571428571)])]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pair_dict.items()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheese'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_next_rhyme(word, temperature, rhymes = False):\n",
    "    d = rhyme_pair_dict if rhymes else word_pair_dict\n",
    "    preds = [x[1] for x in d[word]]\n",
    "\n",
    "    sample_idx = sample(preds, temperature=temperature)\n",
    "    return d[word][sample_idx][0]\n",
    "    \n",
    "get_next_rhyme('please', 1., rhymes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233941"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_paras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair_counter = Counter()\n",
    "\n",
    "too_short = 0\n",
    "\n",
    "common_words = set(word_to_index.keys())\n",
    "\n",
    "punct = {',', '!'}\n",
    "\n",
    "for cp in cleaned_paras:\n",
    "    \n",
    "    lines = cp.split(' [lb] ')\n",
    "    \n",
    "    if len(lines) < 2:\n",
    "        too_short += 1\n",
    "        continue\n",
    "        \n",
    "    for i in range(len(lines) - 1):\n",
    "        line0 = lines[i].split()\n",
    "        line1 = lines[i + 1].split()\n",
    "        \n",
    "        if len(line0) > 3 and len(line1) > 3:\n",
    "            word0 = line0[-1] if line0[-1] not in punct else line0[-2]\n",
    "            word1 = line1[-1] if line1[-1] not in punct else line1[-2]\n",
    "            if word0 != word1 and word0 in common_words and word1 in common_words:\n",
    "                pair_counter[(word0, word1)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('all_words.txt', 'w') as f:\n",
    "    for word in common_words:\n",
    "        f.write(\"%s\\n\" %(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('word_pairs.txt', 'w') as f:\n",
    "    for pair, n in pair_counter.most_common(10000):\n",
    "        f.write(\"%s %s %i\\n\" %(pair[0], pair[1], n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "    def __init__(self, name):\n",
    "        self.__name  = name\n",
    "        self.__links = set()\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "\n",
    "    @property\n",
    "    def links(self):\n",
    "        return set(self.__links)\n",
    "\n",
    "    def add_link(self, other):\n",
    "        self.__links.add(other)\n",
    "        other.__links.add(self)\n",
    "\n",
    "# The function to look for connected components.\n",
    "def connected_components(nodes):\n",
    "\n",
    "    # List of connected components found. The order is random.\n",
    "    result = []\n",
    "\n",
    "    # Make a copy of the set, so we can modify it.\n",
    "    nodes = set(nodes)\n",
    "\n",
    "    # Iterate while we still have nodes to process.\n",
    "    while nodes:\n",
    "\n",
    "        # Get a random node and remove it from the global set.\n",
    "        n = nodes.pop()\n",
    "\n",
    "        # This set will contain the next group of nodes connected to each other.\n",
    "        group = {n}\n",
    "\n",
    "        # Build a queue with this node in it.\n",
    "        queue = [n]\n",
    "\n",
    "        # Iterate the queue.\n",
    "        # When it's empty, we finished visiting a group of connected nodes.\n",
    "        while queue:\n",
    "\n",
    "            # Consume the next item from the queue.\n",
    "            n = queue.pop(0)\n",
    "\n",
    "            # Fetch the neighbors.\n",
    "            neighbors = n.links\n",
    "\n",
    "            # Remove the neighbors we already visited.\n",
    "            neighbors.difference_update(group)\n",
    "\n",
    "            # Remove the remaining nodes from the global set.\n",
    "            nodes.difference_update(neighbors)\n",
    "\n",
    "            # Add them to the group of connected nodes.\n",
    "            group.update(neighbors)\n",
    "\n",
    "            # Add them to the queue, so we visit them in the next iterations.\n",
    "            queue.extend(neighbors)\n",
    "\n",
    "        # Add the group to the list of groups.\n",
    "        result.append(group)\n",
    "\n",
    "    # Return the list of groups.\n",
    "    return result\n",
    "\n",
    "#     # The test code...\n",
    "#     if __name__ == \"__main__\":\n",
    "\n",
    "#         # The first group, let's make a tree.\n",
    "#         a = Data(\"a\")\n",
    "#         b = Data(\"b\")\n",
    "#         c = Data(\"c\")\n",
    "#         d = Data(\"d\")\n",
    "#         e = Data(\"e\")\n",
    "#         f = Data(\"f\")\n",
    "#         a.add_link(b)    #      a\n",
    "#         a.add_link(c)    #     / \\\n",
    "#         b.add_link(d)    #    b   c\n",
    "#         c.add_link(e)    #   /   / \\\n",
    "#         c.add_link(f)    #  d   e   f\n",
    "\n",
    "#         # The second group, let's leave a single, isolated node.\n",
    "#         g = Data(\"g\")\n",
    "\n",
    "#         # The third group, let's make a cycle.\n",
    "#         h = Data(\"h\")\n",
    "#         i = Data(\"i\")\n",
    "#         j = Data(\"j\")\n",
    "#         k = Data(\"k\")\n",
    "#         h.add_link(i)    #    h----i\n",
    "#         i.add_link(j)    #    |    |\n",
    "#         j.add_link(k)    #    |    |\n",
    "#         k.add_link(h)    #    k----j\n",
    "\n",
    "#         # Put all the nodes together in one big set.\n",
    "#         nodes = {a, b, c, d, e, f, g, h, i, j, k}\n",
    "\n",
    "#         # Find all the connected components.\n",
    "#         number = 1\n",
    "#         for components in connected_components(nodes):\n",
    "#             names = sorted(node.name for node in components)\n",
    "#             names = \", \".join(names)\n",
    "#             print \"Group #%i: %s\" % (number, names)\n",
    "#             number += 1\n",
    "\n",
    "#         # You should now see the following output:\n",
    "#         # Group #1: a, b, c, d, e, f\n",
    "#         # Group #2: g\n",
    "#         # Group #3: h, i, j, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that back\n",
      "back that\n",
      "do you\n",
      "me be\n",
      "be me\n",
      "shit bitch\n",
      "you do\n",
      "shit it\n",
      "now down\n",
      "bitch shit\n",
      "it shit\n",
      "down now\n",
      "see me\n",
      "me see\n",
      "that at\n",
      "to you\n",
      "down around\n",
      "too you\n",
      "time mine\n",
      "hood good\n",
      "you too\n",
      "me g\n",
      "around down\n",
      "out about\n",
      "right night\n",
      "at that\n",
      "you to\n",
      "house out\n",
      "know go\n",
      "good hood\n",
      "down town\n",
      "game name\n",
      "about out\n",
      "through you\n",
      "world girl\n",
      "g me\n",
      "mind time\n",
      "you through\n",
      "up fuck\n",
      "out mouth\n",
      "shit dick\n",
      "town down\n",
      "night right\n",
      "life right\n",
      "way day\n",
      "go know\n",
      "me free\n",
      "on gone\n",
      "fuck up\n",
      "time mind\n",
      "\tGroup #0: about, house, mouth, out\n",
      "\tGroup #1: gone, on\n",
      "\tGroup #2: day, way\n",
      "\tGroup #3: bitch, dick, it, shit\n",
      "\tGroup #4: girl, world\n",
      "\tGroup #5: be, free, g, me, see\n",
      "\tGroup #6: around, down, now, town\n",
      "\tGroup #7: at, back, that\n",
      "\tGroup #8: do, through, to, too, you\n",
      "\tGroup #9: mind, mine, time\n",
      "\tGroup #10: good, hood\n",
      "\tGroup #11: life, night, right\n",
      "\tGroup #12: go, know\n",
      "\tGroup #13: game, name\n",
      "\tGroup #14: fuck, up\n",
      "\n",
      "mine time\n",
      "place face\n",
      "free me\n",
      "life wife\n",
      "man hand\n",
      "day way\n",
      "girl world\n",
      "head dead\n",
      "mouth out\n",
      "gone on\n",
      "face place\n",
      "music it\n",
      "at back\n",
      "hand man\n",
      "true you\n",
      "shit with\n",
      "niggas nigga\n",
      "name game\n",
      "back at\n",
      "dead head\n",
      "do crew\n",
      "say way\n",
      "money me\n",
      "right life\n",
      "time rhyme\n",
      "on song\n",
      "cash ass\n",
      "with shit\n",
      "do too\n",
      "now out\n",
      "you true\n",
      "too do\n",
      "baby crazy\n",
      "understand man\n",
      "funny money\n",
      "down sound\n",
      "this it\n",
      "baby me\n",
      "track back\n",
      "dick shit\n",
      "wrong on\n",
      "way say\n",
      "sound down\n",
      "crazy me\n",
      "time line\n",
      "do through\n",
      "money funny\n",
      "em him\n",
      "crack back\n",
      "minute it\n",
      "\tGroup #0: about, around, down, house, mouth, now, out, sound, town\n",
      "\tGroup #1: gone, on, song, wrong\n",
      "\tGroup #2: at, back, crack, that, track\n",
      "\tGroup #3: fuck, up\n",
      "\tGroup #4: dead, head\n",
      "\tGroup #5: bitch, dick, it, minute, music, shit, this, with\n",
      "\tGroup #6: baby, be, crazy, free, funny, g, me, money, see\n",
      "\tGroup #7: crew, do, through, to, too, true, you\n",
      "\tGroup #8: line, mind, mine, rhyme, time\n",
      "\tGroup #9: good, hood\n",
      "\tGroup #10: life, night, right, wife\n",
      "\tGroup #11: go, know\n",
      "\tGroup #12: game, name\n",
      "\tGroup #13: girl, world\n",
      "\tGroup #14: face, place\n",
      "\tGroup #15: hand, man, understand\n",
      "\tGroup #16: nigga, niggas\n",
      "\tGroup #17: day, say, way\n",
      "\tGroup #18: ass, cash\n",
      "\tGroup #19: em, him\n",
      "\n",
      "say day\n",
      "me baby\n",
      "back track\n",
      "rap that\n",
      "bitch rich\n",
      "two you\n",
      "here year\n",
      "game same\n",
      "line time\n",
      "life night\n",
      "black back\n",
      "on wrong\n",
      "back crack\n",
      "day away\n",
      "wrong song\n",
      "shit quick\n",
      "quick shit\n",
      "real feel\n",
      "up enough\n",
      "see be\n",
      "song on\n",
      "that rap\n",
      "it this\n",
      "right tight\n",
      "hit shit\n",
      "doubt out\n",
      "out now\n",
      "crew do\n",
      "crazy baby\n",
      "it with\n",
      "bitch dick\n",
      "off soft\n",
      "man understand\n",
      "d me\n",
      "away day\n",
      "shit hit\n",
      "day say\n",
      "real deal\n",
      "with it\n",
      "rich bitch\n",
      "down round\n",
      "b me\n",
      "me d\n",
      "rhyme time\n",
      "tight right\n",
      "in again\n",
      "up cup\n",
      "one done\n",
      "side ride\n",
      "south mouth\n",
      "\tGroup #0: again, in\n",
      "\tGroup #1: bitch, dick, hit, it, minute, music, quick, rich, shit, this, with\n",
      "\tGroup #2: about, around, doubt, down, house, mouth, now, out, round, sound, south, town\n",
      "\tGroup #3: cup, enough, fuck, up\n",
      "\tGroup #4: game, name, same\n",
      "\tGroup #5: line, mind, mine, rhyme, time\n",
      "\tGroup #6: done, one\n",
      "\tGroup #7: away, day, say, way\n",
      "\tGroup #8: girl, world\n",
      "\tGroup #9: ride, side\n",
      "\tGroup #10: at, back, black, crack, rap, that, track\n",
      "\tGroup #11: dead, head\n",
      "\tGroup #12: deal, feel, real\n",
      "\tGroup #13: hand, man, understand\n",
      "\tGroup #14: crew, do, through, to, too, true, two, you\n",
      "\tGroup #15: here, year\n",
      "\tGroup #16: b, baby, be, crazy, d, free, funny, g, me, money, see\n",
      "\tGroup #17: good, hood\n",
      "\tGroup #18: life, night, right, tight, wife\n",
      "\tGroup #19: go, know\n",
      "\tGroup #20: gone, on, song, wrong\n",
      "\tGroup #21: off, soft\n",
      "\tGroup #22: face, place\n",
      "\tGroup #23: nigga, niggas\n",
      "\tGroup #24: ass, cash\n",
      "\tGroup #25: em, him\n",
      "\n",
      "feel real\n",
      "bitch it\n",
      "out doubt\n",
      "man plan\n",
      "this bitch\n",
      "man can\n",
      "all fall\n",
      "back black\n",
      "face case\n",
      "right tonight\n",
      "out bout\n",
      "on long\n",
      "down ground\n",
      "through do\n",
      "house mouth\n",
      "me money\n",
      "night life\n",
      "it bitch\n",
      "you crew\n",
      "me family\n",
      "bout out\n",
      "me b\n",
      "bed head\n",
      "crew you\n",
      "long on\n",
      "on home\n",
      "again in\n",
      "home on\n",
      "me p\n",
      "ass cash\n",
      "you two\n",
      "me crazy\n",
      "flow know\n",
      "cut up\n",
      "soft off\n",
      "cup up\n",
      "head bed\n",
      "be see\n",
      "ground down\n",
      "up truck\n",
      "him em\n",
      "know show\n",
      "plan man\n",
      "day play\n",
      "right fight\n",
      "door floor\n",
      "game fame\n",
      "go show\n",
      "same game\n",
      "home alone\n",
      "\tGroup #0: flow, go, know, show\n",
      "\tGroup #1: again, in\n",
      "\tGroup #2: bitch, dick, hit, it, minute, music, quick, rich, shit, this, with\n",
      "\tGroup #3: cup, cut, enough, fuck, truck, up\n",
      "\tGroup #4: about, around, bout, doubt, down, ground, house, mouth, now, out, round, sound, south, town\n",
      "\tGroup #5: fame, game, name, same\n",
      "\tGroup #6: fight, life, night, right, tight, tonight, wife\n",
      "\tGroup #7: line, mind, mine, rhyme, time\n",
      "\tGroup #8: done, one\n",
      "\tGroup #9: girl, world\n",
      "\tGroup #10: ass, cash\n",
      "\tGroup #11: ride, side\n",
      "\tGroup #12: at, back, black, crack, rap, that, track\n",
      "\tGroup #13: door, floor\n",
      "\tGroup #14: away, day, play, say, way\n",
      "\tGroup #15: bed, dead, head\n",
      "\tGroup #16: can, hand, man, plan, understand\n",
      "\tGroup #17: deal, feel, real\n",
      "\tGroup #18: crew, do, through, to, too, true, two, you\n",
      "\tGroup #19: here, year\n",
      "\tGroup #20: b, baby, be, crazy, d, family, free, funny, g, me, money, p, see\n",
      "\tGroup #21: all, fall\n",
      "\tGroup #22: alone, gone, home, long, on, song, wrong\n",
      "\tGroup #23: case, face, place\n",
      "\tGroup #24: nigga, niggas\n",
      "\tGroup #25: good, hood\n",
      "\tGroup #26: off, soft\n",
      "\tGroup #27: em, him\n",
      "\n",
      "done one\n",
      "black that\n",
      "alone home\n",
      "dick bitch\n",
      "to do\n",
      "hard god\n",
      "can man\n",
      "death breath\n",
      "me three\n",
      "son one\n",
      "up cut\n",
      "way play\n",
      "me streets\n",
      "ride side\n",
      "heart apart\n",
      "there care\n",
      "flow go\n",
      "shit get\n",
      "one son\n",
      "fight right\n",
      "strong on\n",
      "play way\n",
      "do to\n",
      "me do\n",
      "night tight\n",
      "streets me\n",
      "rap back\n",
      "again friend\n",
      "round down\n",
      "game change\n",
      "tonight right\n",
      "time shine\n",
      "light right\n",
      "top stop\n",
      "two do\n",
      "like right\n",
      "mouth south\n",
      "mouth house\n",
      "hoes clothes\n",
      "back rap\n",
      "tight night\n",
      "down clown\n",
      "change game\n",
      "know flow\n",
      "death left\n",
      "on strong\n",
      "fall all\n",
      "down pound\n",
      "shine mine\n",
      "world girls\n",
      "\tGroup #0: bitch, dick, get, hit, it, minute, music, quick, rich, shit, this, with\n",
      "\tGroup #1: alone, gone, home, long, on, song, strong, wrong\n",
      "\tGroup #2: again, friend, in\n",
      "\tGroup #3: flow, go, know, show\n",
      "\tGroup #4: change, fame, game, name, same\n",
      "\tGroup #5: line, mind, mine, rhyme, shine, time\n",
      "\tGroup #6: fight, life, light, like, night, right, tight, tonight, wife\n",
      "\tGroup #7: stop, top\n",
      "\tGroup #8: b, baby, be, crazy, crew, d, do, family, free, funny, g, me, money, p, see, streets, three, through, to, too, true, two, you\n",
      "\tGroup #9: clothes, hoes\n",
      "\tGroup #10: about, around, bout, clown, doubt, down, ground, house, mouth, now, out, pound, round, sound, south, town\n",
      "\tGroup #11: breath, death, left\n",
      "\tGroup #12: girl, girls, world\n",
      "\tGroup #13: cup, cut, enough, fuck, truck, up\n",
      "\tGroup #14: can, hand, man, plan, understand\n",
      "\tGroup #15: at, back, black, crack, rap, that, track\n",
      "\tGroup #16: here, year\n",
      "\tGroup #17: done, one, son\n",
      "\tGroup #18: away, day, play, say, way\n",
      "\tGroup #19: deal, feel, real\n",
      "\tGroup #20: good, hood\n",
      "\tGroup #21: case, face, place\n",
      "\tGroup #22: off, soft\n",
      "\tGroup #23: ride, side\n",
      "\tGroup #24: all, fall\n",
      "\tGroup #25: door, floor\n",
      "\tGroup #26: bed, dead, head\n",
      "\tGroup #27: apart, heart\n",
      "\tGroup #28: nigga, niggas\n",
      "\tGroup #29: ass, cash\n",
      "\tGroup #30: em, him\n",
      "\tGroup #31: god, hard\n",
      "\tGroup #32: care, there\n",
      "\n",
      "that black\n",
      "me e\n",
      "homie me\n",
      "heart start\n",
      "city me\n",
      "floor more\n",
      "case face\n",
      "spit shit\n",
      "ass fast\n",
      "around town\n",
      "me homie\n",
      "high die\n",
      "left death\n",
      "right like\n",
      "show go\n",
      "play day\n",
      "go flow\n",
      "real steel\n",
      "do two\n",
      "clear here\n",
      "deal real\n",
      "hot spot\n",
      "right light\n",
      "there here\n",
      "kid did\n",
      "e me\n",
      "bread head\n",
      "night fight\n",
      "all ball\n",
      "it minute\n",
      "mine line\n",
      "air care\n",
      "c me\n",
      "p me\n",
      "drama mama\n",
      "line mine\n",
      "em them\n",
      "talk walk\n",
      "street me\n",
      "time rhymes\n",
      "said head\n",
      "true do\n",
      "quit shit\n",
      "for more\n",
      "here there\n",
      "block rock\n",
      "stop top\n",
      "shine time\n",
      "back me\n",
      "wife life\n",
      "\tGroup #0: bitch, dick, get, hit, it, minute, music, quick, quit, rich, shit, spit, this, with\n",
      "\tGroup #1: alone, gone, home, long, on, song, strong, wrong\n",
      "\tGroup #2: again, friend, in\n",
      "\tGroup #3: flow, go, know, show\n",
      "\tGroup #4: change, fame, game, name, same\n",
      "\tGroup #5: line, mind, mine, rhyme, rhymes, shine, time\n",
      "\tGroup #6: fight, life, light, like, night, right, tight, tonight, wife\n",
      "\tGroup #7: stop, top\n",
      "\tGroup #8: at, b, baby, back, be, black, c, city, crack, crazy, crew, d, do, e, family, free, funny, g, homie, me, money, p, rap, see, street, streets, that, three, through, to, too, track, true, two, you\n",
      "\tGroup #9: clothes, hoes\n",
      "\tGroup #10: about, around, bout, clown, doubt, down, ground, house, mouth, now, out, pound, round, sound, south, town\n",
      "\tGroup #11: breath, death, left\n",
      "\tGroup #12: girl, girls, world\n",
      "\tGroup #13: away, day, play, say, way\n",
      "\tGroup #14: apart, heart, start\n",
      "\tGroup #15: door, floor, for, more\n",
      "\tGroup #16: ass, cash, fast\n",
      "\tGroup #17: die, high\n",
      "\tGroup #18: deal, feel, real, steel\n",
      "\tGroup #19: air, care, clear, here, there, year\n",
      "\tGroup #20: hot, spot\n",
      "\tGroup #21: did, kid\n",
      "\tGroup #22: bed, bread, dead, head, said\n",
      "\tGroup #23: all, ball, fall\n",
      "\tGroup #24: drama, mama\n",
      "\tGroup #25: em, him, them\n",
      "\tGroup #26: talk, walk\n",
      "\tGroup #27: block, rock\n",
      "\tGroup #28: cup, cut, enough, fuck, truck, up\n",
      "\tGroup #29: god, hard\n",
      "\tGroup #30: good, hood\n",
      "\tGroup #31: case, face, place\n",
      "\tGroup #32: off, soft\n",
      "\tGroup #33: done, one, son\n",
      "\tGroup #34: ride, side\n",
      "\tGroup #35: can, hand, man, plan, understand\n",
      "\tGroup #36: nigga, niggas\n",
      "\n",
      "fly die\n",
      "fame game\n",
      "head said\n",
      "too through\n",
      "name same\n",
      "one gun\n",
      "gun one\n",
      "easy me\n",
      "phone home\n",
      "town around\n",
      "know hoe\n",
      "bitch this\n",
      "floor door\n",
      "pocket it\n",
      "truck up\n",
      "do true\n",
      "know me\n",
      "through too\n",
      "family me\n",
      "cool school\n",
      "it pocket\n",
      "gun run\n",
      "bitches riches\n",
      "crack that\n",
      "three me\n",
      "here fear\n",
      "care there\n",
      "gone home\n",
      "star car\n",
      "love above\n",
      "good wood\n",
      "me c\n",
      "high by\n",
      "door more\n",
      "song wrong\n",
      "baby lady\n",
      "song long\n",
      "more door\n",
      "now how\n",
      "real kill\n",
      "streets beats\n",
      "fame name\n",
      "shit click\n",
      "street beat\n",
      "together forever\n",
      "away say\n",
      "more for\n",
      "me easy\n",
      "me tv\n",
      "fight night\n",
      "\tGroup #0: bitch, click, dick, get, hit, it, minute, music, pocket, quick, quit, rich, shit, spit, this, with\n",
      "\tGroup #1: alone, gone, home, long, on, phone, song, strong, wrong\n",
      "\tGroup #2: again, friend, in\n",
      "\tGroup #3: at, b, baby, back, be, beat, beats, black, c, city, crack, crazy, crew, d, do, e, easy, family, flow, free, funny, g, go, hoe, homie, know, lady, me, money, p, rap, see, show, street, streets, that, three, through, to, too, track, true, tv, two, you\n",
      "\tGroup #4: change, fame, game, name, same\n",
      "\tGroup #5: line, mind, mine, rhyme, rhymes, shine, time\n",
      "\tGroup #6: fight, life, light, like, night, right, tight, tonight, wife\n",
      "\tGroup #7: stop, top\n",
      "\tGroup #8: clothes, hoes\n",
      "\tGroup #9: about, around, bout, clown, doubt, down, ground, house, how, mouth, now, out, pound, round, sound, south, town\n",
      "\tGroup #10: breath, death, left\n",
      "\tGroup #11: girl, girls, world\n",
      "\tGroup #12: away, day, play, say, way\n",
      "\tGroup #13: apart, heart, start\n",
      "\tGroup #14: door, floor, for, more\n",
      "\tGroup #15: ass, cash, fast\n",
      "\tGroup #16: by, die, fly, high\n",
      "\tGroup #17: deal, feel, kill, real, steel\n",
      "\tGroup #18: air, care, clear, fear, here, there, year\n",
      "\tGroup #19: hot, spot\n",
      "\tGroup #20: did, kid\n",
      "\tGroup #21: bed, bread, dead, head, said\n",
      "\tGroup #22: all, ball, fall\n",
      "\tGroup #23: drama, mama\n",
      "\tGroup #24: em, him, them\n",
      "\tGroup #25: talk, walk\n",
      "\tGroup #26: block, rock\n",
      "\tGroup #27: done, gun, one, run, son\n",
      "\tGroup #28: cool, school\n",
      "\tGroup #29: cup, cut, enough, fuck, truck, up\n",
      "\tGroup #30: bitches, riches\n",
      "\tGroup #31: car, star\n",
      "\tGroup #32: above, love\n",
      "\tGroup #33: good, hood, wood\n",
      "\tGroup #34: god, hard\n",
      "\tGroup #35: forever, together\n",
      "\tGroup #36: case, face, place\n",
      "\tGroup #37: off, soft\n",
      "\tGroup #38: ride, side\n",
      "\tGroup #39: can, hand, man, plan, understand\n",
      "\tGroup #40: nigga, niggas\n",
      "\n",
      "shit rich\n",
      "more floor\n",
      "is kids\n",
      "class ass\n",
      "around sound\n",
      "stop drop\n",
      "money honey\n",
      "stand man\n",
      "say away\n",
      "click shit\n",
      "game pain\n",
      "t me\n",
      "year here\n",
      "you boo\n",
      "key me\n",
      "home phone\n",
      "friend again\n",
      "shit spit\n",
      "block glock\n",
      "to through\n",
      "die fly\n",
      "through to\n",
      "show know\n",
      "grind time\n",
      "well hell\n",
      "mind mine\n",
      "out south\n",
      "wrong gone\n",
      "this is\n",
      "that crack\n",
      "about mouth\n",
      "me city\n",
      "one fun\n",
      "away today\n",
      "weed me\n",
      "good would\n",
      "life knife\n",
      "beat street\n",
      "cool fool\n",
      "pain rain\n",
      "spot hot\n",
      "track that\n",
      "head bread\n",
      "me key\n",
      "nigga bigger\n",
      "days ways\n",
      "work hurt\n",
      "friends ends\n",
      "down crown\n",
      "walk talk\n",
      "\tGroup #0: bitch, click, dick, get, hit, is, it, kids, minute, music, pocket, quick, quit, rich, shit, spit, this, with\n",
      "\tGroup #1: done, fun, gun, one, run, son\n",
      "\tGroup #2: alone, gone, home, long, on, phone, song, strong, wrong\n",
      "\tGroup #3: again, friend, in\n",
      "\tGroup #4: at, b, baby, back, be, beat, beats, black, boo, c, city, crack, crazy, crew, d, do, e, easy, family, flow, free, funny, g, go, hoe, homie, honey, key, know, lady, me, money, p, rap, see, show, street, streets, t, that, three, through, to, too, track, true, tv, two, weed, you\n",
      "\tGroup #5: change, fame, game, name, pain, rain, same\n",
      "\tGroup #6: grind, line, mind, mine, rhyme, rhymes, shine, time\n",
      "\tGroup #7: fight, knife, life, light, like, night, right, tight, tonight, wife\n",
      "\tGroup #8: girl, girls, world\n",
      "\tGroup #9: bed, bread, dead, head, said\n",
      "\tGroup #10: cup, cut, enough, fuck, truck, up\n",
      "\tGroup #11: by, die, fly, high\n",
      "\tGroup #12: all, ball, fall\n",
      "\tGroup #13: about, around, bout, clown, crown, doubt, down, ground, house, how, mouth, now, out, pound, round, sound, south, town\n",
      "\tGroup #14: deal, feel, kill, real, steel\n",
      "\tGroup #15: forever, together\n",
      "\tGroup #16: ass, cash, class, fast\n",
      "\tGroup #17: case, face, place\n",
      "\tGroup #18: drop, stop, top\n",
      "\tGroup #19: can, hand, man, plan, stand, understand\n",
      "\tGroup #20: block, glock, rock\n",
      "\tGroup #21: hell, well\n",
      "\tGroup #22: away, day, play, say, today, way\n",
      "\tGroup #23: good, hood, wood, would\n",
      "\tGroup #24: cool, fool, school\n",
      "\tGroup #25: bigger, nigga, niggas\n",
      "\tGroup #26: days, ways\n",
      "\tGroup #27: hurt, work\n",
      "\tGroup #28: ends, friends\n",
      "\tGroup #29: clothes, hoes\n",
      "\tGroup #30: breath, death, left\n",
      "\tGroup #31: apart, heart, start\n",
      "\tGroup #32: door, floor, for, more\n",
      "\tGroup #33: air, care, clear, fear, here, there, year\n",
      "\tGroup #34: hot, spot\n",
      "\tGroup #35: did, kid\n",
      "\tGroup #36: drama, mama\n",
      "\tGroup #37: em, him, them\n",
      "\tGroup #38: talk, walk\n",
      "\tGroup #39: bitches, riches\n",
      "\tGroup #40: car, star\n",
      "\tGroup #41: above, love\n",
      "\tGroup #42: off, soft\n",
      "\tGroup #43: ride, side\n",
      "\tGroup #44: god, hard\n",
      "\n",
      "start heart\n",
      "blue you\n",
      "boo you\n",
      "heat street\n",
      "breath death\n",
      "night light\n",
      "shit clip\n",
      "this miss\n",
      "is it\n",
      "live give\n",
      "fun one\n",
      "die cry\n",
      "know blow\n",
      "back attack\n",
      "light night\n",
      "pain game\n",
      "point joint\n",
      "nothin somethin\n",
      "die high\n",
      "ways days\n",
      "back act\n",
      "cry die\n",
      "gone wrong\n",
      "man hands\n",
      "long song\n",
      "up nuts\n",
      "fact back\n",
      "home gone\n",
      "shit quit\n",
      "play say\n",
      "way away\n",
      "before more\n",
      "block stop\n",
      "run gun\n",
      "rich shit\n",
      "day pay\n",
      "here clear\n",
      "all wall\n",
      "wall all\n",
      "said dead\n",
      "deep sleep\n",
      "game brain\n",
      "street heat\n",
      "name fame\n",
      "tv me\n",
      "time crime\n",
      "south out\n",
      "him them\n",
      "time grind\n",
      "you that\n",
      "\tGroup #0: joint, point\n",
      "\tGroup #1: bitch, click, clip, dick, get, hit, is, it, kids, minute, miss, music, pocket, quick, quit, rich, shit, spit, this, with\n",
      "\tGroup #2: done, fun, gun, one, run, son\n",
      "\tGroup #3: alone, gone, home, long, on, phone, song, strong, wrong\n",
      "\tGroup #4: again, friend, in\n",
      "\tGroup #5: can, hand, hands, man, plan, stand, understand\n",
      "\tGroup #6: brain, change, fame, game, name, pain, rain, same\n",
      "\tGroup #7: crime, grind, line, mind, mine, rhyme, rhymes, shine, time\n",
      "\tGroup #8: fight, knife, life, light, like, night, right, tight, tonight, wife\n",
      "\tGroup #9: block, drop, glock, rock, stop, top\n",
      "\tGroup #10: about, around, bout, clown, crown, doubt, down, ground, house, how, mouth, now, out, pound, round, sound, south, town\n",
      "\tGroup #11: by, cry, die, fly, high\n",
      "\tGroup #12: em, him, them\n",
      "\tGroup #13: ride, side\n",
      "\tGroup #14: act, at, attack, b, baby, back, be, beat, beats, black, blow, blue, boo, c, city, crack, crazy, crew, d, do, e, easy, fact, family, flow, free, funny, g, go, heat, hoe, homie, honey, key, know, lady, me, money, p, rap, see, show, street, streets, t, that, three, through, to, too, track, true, tv, two, weed, you\n",
      "\tGroup #15: girl, girls, world\n",
      "\tGroup #16: bed, bread, dead, head, said\n",
      "\tGroup #17: deal, feel, kill, real, steel\n",
      "\tGroup #18: forever, together\n",
      "\tGroup #19: ass, cash, class, fast\n",
      "\tGroup #20: case, face, place\n",
      "\tGroup #21: hell, well\n",
      "\tGroup #22: away, day, pay, play, say, today, way\n",
      "\tGroup #23: good, hood, wood, would\n",
      "\tGroup #24: cool, fool, school\n",
      "\tGroup #25: bigger, nigga, niggas\n",
      "\tGroup #26: days, ways\n",
      "\tGroup #27: hurt, work\n",
      "\tGroup #28: ends, friends\n",
      "\tGroup #29: give, live\n",
      "\tGroup #30: nothin, somethin\n",
      "\tGroup #31: cup, cut, enough, fuck, nuts, truck, up\n",
      "\tGroup #32: before, door, floor, for, more\n",
      "\tGroup #33: all, ball, fall, wall\n",
      "\tGroup #34: deep, sleep\n",
      "\tGroup #35: clothes, hoes\n",
      "\tGroup #36: breath, death, left\n",
      "\tGroup #37: apart, heart, start\n",
      "\tGroup #38: air, care, clear, fear, here, there, year\n",
      "\tGroup #39: hot, spot\n",
      "\tGroup #40: did, kid\n",
      "\tGroup #41: drama, mama\n",
      "\tGroup #42: talk, walk\n",
      "\tGroup #43: bitches, riches\n",
      "\tGroup #44: car, star\n",
      "\tGroup #45: above, love\n",
      "\tGroup #46: god, hard\n",
      "\tGroup #47: off, soft\n",
      "\n",
      "face taste\n",
      "club up\n",
      "chance dance\n",
      "same name\n",
      "did kid\n",
      "rhymes time\n",
      "park dark\n",
      "mind line\n",
      "again friends\n",
      "life like\n",
      "life twice\n",
      "clown down\n",
      "us bust\n",
      "me mc\n",
      "long gone\n",
      "that nigga\n",
      "above love\n",
      "past ass\n",
      "crew too\n",
      "years tears\n",
      "wrong long\n",
      "air there\n",
      "it right\n",
      "what me\n",
      "long strong\n",
      "ball all\n",
      "friends again\n",
      "dirt work\n",
      "alone phone\n",
      "zone home\n",
      "streets heat\n",
      "mind grind\n",
      "girls world\n",
      "me t\n",
      "say play\n",
      "me pussy\n",
      "around now\n",
      "out you\n",
      "drop stop\n",
      "live kids\n",
      "benz friends\n",
      "today away\n",
      "way today\n",
      "car star\n",
      "school cool\n",
      "nigga trigger\n",
      "pen again\n",
      "evil people\n",
      "you ya\n",
      "clothes hoes\n",
      "\tGroup #0: joint, point\n",
      "\tGroup #1: bitch, click, clip, dick, fight, get, give, hit, is, it, kids, knife, life, light, like, live, minute, miss, music, night, pocket, quick, quit, rich, right, shit, spit, this, tight, tonight, twice, wife, with\n",
      "\tGroup #2: done, fun, gun, one, run, son\n",
      "\tGroup #3: alone, gone, home, long, on, phone, song, strong, wrong, zone\n",
      "\tGroup #4: again, benz, ends, friend, friends, in, pen\n",
      "\tGroup #5: can, hand, hands, man, plan, stand, understand\n",
      "\tGroup #6: brain, change, fame, game, name, pain, rain, same\n",
      "\tGroup #7: crime, grind, line, mind, mine, rhyme, rhymes, shine, time\n",
      "\tGroup #8: about, act, around, at, attack, b, baby, back, be, beat, beats, bigger, black, blow, blue, boo, bout, c, city, clown, crack, crazy, crew, crown, d, do, doubt, down, e, easy, fact, family, flow, free, funny, g, go, ground, heat, hoe, homie, honey, house, how, key, know, lady, mc, me, money, mouth, nigga, niggas, now, out, p, pound, pussy, rap, round, see, show, sound, south, street, streets, t, that, three, through, to, too, town, track, trigger, true, tv, two, weed, what, ya, you\n",
      "\tGroup #9: em, him, them\n",
      "\tGroup #10: girl, girls, world\n",
      "\tGroup #11: bed, bread, dead, head, said\n",
      "\tGroup #12: case, face, place, taste\n",
      "\tGroup #13: all, ball, fall, wall\n",
      "\tGroup #14: chance, dance\n",
      "\tGroup #15: dark, park\n",
      "\tGroup #16: forever, together\n",
      "\tGroup #17: ass, cash, class, fast, past\n",
      "\tGroup #18: tears, years\n",
      "\tGroup #19: block, drop, glock, rock, stop, top\n",
      "\tGroup #20: evil, people\n",
      "\tGroup #21: hell, well\n",
      "\tGroup #22: away, day, pay, play, say, today, way\n",
      "\tGroup #23: good, hood, wood, would\n",
      "\tGroup #24: cool, fool, school\n",
      "\tGroup #25: days, ways\n",
      "\tGroup #26: dirt, hurt, work\n",
      "\tGroup #27: by, cry, die, fly, high\n",
      "\tGroup #28: nothin, somethin\n",
      "\tGroup #29: club, cup, cut, enough, fuck, nuts, truck, up\n",
      "\tGroup #30: before, door, floor, for, more\n",
      "\tGroup #31: deep, sleep\n",
      "\tGroup #32: clothes, hoes\n",
      "\tGroup #33: breath, death, left\n",
      "\tGroup #34: apart, heart, start\n",
      "\tGroup #35: deal, feel, kill, real, steel\n",
      "\tGroup #36: air, care, clear, fear, here, there, year\n",
      "\tGroup #37: hot, spot\n",
      "\tGroup #38: did, kid\n",
      "\tGroup #39: drama, mama\n",
      "\tGroup #40: talk, walk\n",
      "\tGroup #41: bust, us\n",
      "\tGroup #42: bitches, riches\n",
      "\tGroup #43: car, star\n",
      "\tGroup #44: above, love\n",
      "\tGroup #45: god, hard\n",
      "\tGroup #46: off, soft\n",
      "\tGroup #47: ride, side\n",
      "\n",
      "hands man\n",
      "story me\n",
      "life tonight\n",
      "bad had\n",
      "back sack\n",
      "nigga ya\n",
      "ride inside\n",
      "lady baby\n",
      "up butt\n",
      "to too\n",
      "sky die\n",
      "top drop\n",
      "one run\n",
      "down brown\n",
      "again win\n",
      "high fly\n",
      "know dough\n",
      "hot not\n",
      "me history\n",
      "style wild\n",
      "wrong strong\n",
      "game chain\n",
      "riches bitches\n",
      "hoe go\n",
      "hood wood\n",
      "dick it\n",
      "mind shine\n",
      "slow go\n",
      "land man\n",
      "now around\n",
      "level devil\n",
      "fear here\n",
      "there hair\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for line in open('word_pairs').read().split('\\n'):\n",
    "    if line.startswith('*'):\n",
    "        print(\"stop\")\n",
    "        break\n",
    "    w0, w1, n = line.split()\n",
    "    print (w0, w1)\n",
    "    for w in (w0, w1):\n",
    "        if w not in data_dict:\n",
    "            data_dict[w] = Data(w)\n",
    "    data_dict[w0].add_link(data_dict[w1])\n",
    "    data_dict[w1].add_link(data_dict[w0])\n",
    "    \n",
    "    counter += 1\n",
    "    if counter % 50 == 0:\n",
    "        nodes = data_dict.values()\n",
    "        for number, components in enumerate(connected_components(nodes)):\n",
    "            names = sorted(node.name for node in components)\n",
    "            names = \", \".join(names)\n",
    "            print(\"\\tGroup #%i: %s\" % (number, names))\n",
    "        print()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group #0: about, act, around, at, attack, b, baby, back, be, beat, beats, bigger, bitch, black, blow, blue, boo, bout, brown, butt, c, city, click, clip, clown, club, crack, crazy, crew, crown, cup, cut, d, dick, do, doubt, dough, down, e, easy, enough, fact, family, fight, flow, free, fuck, funny, g, get, give, go, ground, heat, history, hit, hoe, homie, honey, house, how, is, it, key, kids, knife, know, lady, life, light, like, live, mc, me, minute, miss, money, mouth, music, nigga, niggas, night, now, nuts, out, p, pocket, pound, pussy, quick, quit, rap, rich, right, round, sack, see, shit, show, slow, sound, south, spit, story, street, streets, t, that, this, three, through, tight, to, tonight, too, town, track, trigger, truck, true, tv, twice, two, up, weed, what, wife, with, ya, you\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'about, act, around, at, attack, b, baby, back, be, beat, beats, bigger, bitch, black, blow, blue, boo, bout, brown, butt, c, city, click, clip, clown, club, crack, crazy, crew, crown, cup, cut, d, dick, do, doubt, dough, down, e, easy, enough, fact, family, fight, flow, free, fuck, funny, g, get, give, go, ground, heat, history, hit, hoe, homie, honey, house, how, is, it, key, kids, knife, know, lady, life, light, like, live, mc, me, minute, miss, money, mouth, music, nigga, niggas, night, now, nuts, out, p, pocket, pound, pussy, quick, quit, rap, rich, right, round, sack, see, shit, show, slow, sound, south, spit, story, street, streets, t, that, this, three, through, tight, to, tonight, too, town, track, trigger, truck, true, tv, twice, two, up, weed, what, wife, with, ya, you'"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that back\n",
      "back that\n",
      "do you\n",
      "me be\n",
      "be me\n",
      "shit bitch\n",
      "you do\n",
      "shit it\n",
      "now down\n",
      "bitch shit\n",
      "it shit\n",
      "down now\n",
      "see me\n",
      "me see\n",
      "that at\n",
      "to you\n",
      "down around\n",
      "you me\n",
      "me you\n",
      "too you\n",
      "you too\n",
      "me g\n",
      "around down\n",
      "out about\n",
      "right night\n",
      "at that\n",
      "you to\n",
      "house out\n",
      "know go\n",
      "down town\n",
      "about out\n",
      "through you\n",
      "g me\n",
      "you through\n",
      "up fuck\n",
      "out mouth\n",
      "shit dick\n",
      "town down\n",
      "night right\n",
      "life right\n",
      "go know\n",
      "me free\n",
      "fuck up\n",
      "free me\n",
      "life wife\n",
      "mouth out\n",
      "music it\n",
      "at back\n",
      "true you\n",
      "shit with\n",
      "niggas nigga\n",
      "back at\n",
      "do crew\n",
      "money me\n",
      "right life\n",
      "with shit\n",
      "do too\n",
      "now out\n",
      "you true\n",
      "too do\n",
      "baby crazy\n",
      "funny money\n",
      "down sound\n",
      "this it\n",
      "baby me\n",
      "track back\n",
      "dick shit\n",
      "sound down\n",
      "crazy me\n",
      "do through\n",
      "money funny\n",
      "crack back\n",
      "minute it\n",
      "me baby\n",
      "back track\n",
      "rap that\n",
      "bitch rich\n",
      "two you\n",
      "life night\n",
      "black back\n",
      "back crack\n",
      "shit quick\n",
      "quick shit\n",
      "up enough\n",
      "see be\n",
      "me that\n",
      "that rap\n",
      "it this\n",
      "shit up\n",
      "right tight\n",
      "hit shit\n",
      "doubt out\n",
      "out now\n",
      "crew do\n",
      "crazy baby\n",
      "it with\n",
      "bitch dick\n",
      "d me\n",
      "shit hit\n",
      "with it\n",
      "rich bitch\n",
      "down round\n",
      "b me\n",
      "me d\n",
      "tight right\n",
      "up cup\n",
      "south mouth\n",
      "bitch it\n",
      "out doubt\n",
      "this bitch\n",
      "back black\n",
      "right tonight\n",
      "out bout\n",
      "down ground\n",
      "through do\n",
      "house mouth\n",
      "me money\n",
      "night life\n",
      "it bitch\n",
      "you crew\n",
      "me family\n",
      "bout out\n",
      "me b\n",
      "crew you\n",
      "me p\n",
      "you two\n",
      "me crazy\n",
      "flow know\n",
      "cut up\n",
      "cup up\n",
      "be see\n",
      "ground down\n",
      "up truck\n",
      "know show\n",
      "out it\n",
      "right fight\n",
      "go show\n",
      "black that\n",
      "dick bitch\n",
      "to do\n",
      "me three\n",
      "up cut\n",
      "me streets\n",
      "flow go\n",
      "shit get\n",
      "fight right\n",
      "do to\n",
      "me do\n",
      "night tight\n",
      "streets me\n",
      "rap back\n",
      "round down\n",
      "tonight right\n",
      "light right\n",
      "two do\n",
      "like right\n",
      "mouth south\n",
      "mouth house\n",
      "back rap\n",
      "tight night\n",
      "down clown\n",
      "know flow\n",
      "down pound\n",
      "that black\n",
      "me e\n",
      "homie me\n",
      "city me\n",
      "spit shit\n",
      "around town\n",
      "me homie\n",
      "right like\n",
      "show go\n",
      "go flow\n",
      "do two\n",
      "right light\n",
      "e me\n",
      "night fight\n",
      "it minute\n",
      "c me\n",
      "p me\n",
      "street me\n",
      "true do\n",
      "quit shit\n",
      "back me\n",
      "wife life\n",
      "too through\n",
      "easy me\n",
      "town around\n",
      "know hoe\n",
      "bitch this\n",
      "pocket it\n",
      "truck up\n",
      "do true\n",
      "know me\n",
      "through too\n",
      "family me\n",
      "it pocket\n",
      "crack that\n",
      "three me\n",
      "me c\n",
      "baby lady\n",
      "now how\n",
      "streets beats\n",
      "shit click\n",
      "street beat\n",
      "me easy\n",
      "me tv\n",
      "fight night\n",
      "shit rich\n",
      "is kids\n",
      "around sound\n",
      "money honey\n",
      "click shit\n",
      "t me\n",
      "you boo\n",
      "key me\n",
      "shit spit\n",
      "to through\n",
      "through to\n",
      "show know\n",
      "out south\n",
      "this is\n",
      "that crack\n",
      "about mouth\n",
      "me city\n",
      "one fun\n",
      "weed me\n",
      "life knife\n",
      "beat street\n",
      "track that\n",
      "me key\n",
      "nigga bigger\n",
      "down crown\n",
      "blue you\n",
      "boo you\n",
      "heat street\n",
      "night light\n",
      "shit clip\n",
      "this miss\n",
      "is it\n",
      "live give\n",
      "fun one\n",
      "know blow\n",
      "back attack\n",
      "light night\n",
      "back act\n",
      "up nuts\n",
      "fact back\n",
      "shit quit\n",
      "rich shit\n",
      "street heat\n",
      "tv me\n",
      "south out\n",
      "you that\n",
      "club up\n",
      "life like\n",
      "life twice\n",
      "clown down\n",
      "me mc\n",
      "that nigga\n",
      "crew too\n",
      "it right\n",
      "what me\n",
      "streets heat\n",
      "me t\n",
      "me pussy\n",
      "around now\n",
      "out you\n",
      "live kids\n",
      "nigga trigger\n",
      "you ya\n",
      "story me\n",
      "life tonight\n",
      "back sack\n",
      "nigga ya\n",
      "lady baby\n",
      "up butt\n",
      "to too\n",
      "down brown\n",
      "know dough\n",
      "me history\n",
      "hoe go\n",
      "dick it\n",
      "slow go\n",
      "now around\n",
      "stop\n"
     ]
    }
   ],
   "source": [
    "for line in open('word_pairs').read().split('\\n'):\n",
    "    if line.startswith('*'):\n",
    "        print(\"stop\")\n",
    "        break\n",
    "    w0, w1, n = line.split()\n",
    "    if w0 in names and w1 in names:\n",
    "        print(\"%s %s\" %(w0, w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def moving_average(a, n=16) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "Iteration 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEACAYAAABCl1qQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZFhIkpoMC0lS0/8DzSrgeX9nXMkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11b363ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 319/10646 [00:29<14:36, 11.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KEYBOARD INTERRUPT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11b4f9cb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# train the model, output generated text after each iteration\n",
    "try:\n",
    "    for iteration in range(0, 3):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "\n",
    "        for i in tqdm(range(len(sentences) / BATCH_SIZE)):\n",
    "            X_, y_ = train_iter.next()\n",
    "            errs.append(model.train_on_batch(X_, y_))\n",
    "\n",
    "            if i % 2 == 0:\n",
    "                X_, y_ = val_iter.next()\n",
    "                val_errs.append(model.evaluate(X_, y_, verbose=False))\n",
    "\n",
    "\n",
    "            if i % 5000 == 0:\n",
    "                filepath = \"saved_model_%i.keras\" %i\n",
    "                model.save(filepath)\n",
    "                a = moving_average(errs, n = 100)\n",
    "                plt.plot(range(len(a)), a)\n",
    "                a = moving_average(val_errs, n = 100 / 2)\n",
    "                plt.plot(range(0, len(a) * 2, 2), a)\n",
    "                plt.show()\n",
    "                if i > 0 and i % 10000 == 0:\n",
    "                    lr = float(K.get_value(optimizer.lr))\n",
    "                    new_lr = lr * 0.7\n",
    "                    K.set_value(optimizer.lr, new_lr)\n",
    "                    print(\"new learning rate : %.5f\" %new_lr)\n",
    "\n",
    "        #model.fit(X, y, batch_size=128, nb_epoch=1)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"KEYBOARD INTERRUPT\")\n",
    "    a = moving_average(errs, n = 100)\n",
    "    plt.plot(range(len(a)), a)\n",
    "    a = moving_average(val_errs, n = 100 / 2)\n",
    "    plt.plot(range(0, len(a) * 2, 2), a)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = \"rapbot_v2.keras\"\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.load_model(\"rapbot_v1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_para(cp):\n",
    "    return np.mean([rare_ranks.get(w, 0) < 5000 for w in cp.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f19459ed5d0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8P8BTfg9kyP1vhEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1945ac3bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(len(cleaned_paras)), [scores[i] for i in sorted_scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya know chopper city got all they reasons [lb] you know what i'm saying for doing the things they do [lb] know what i'm saying and imma tell you like this here [lb] if you ain't real know what i'm saying we really ain't [lb] got nothing in common know what i'm saying so its like this\n",
      "\n",
      "she got that million dollar [lb] million dollar oow , oow [lb] she got that million dollar [lb] million dollar oow , oow [lb] and all i want to do is touch it oow , oow [lb] make her tapout , tapout , tapout , tapout , tapout [lb] and i'm gon make her tapout , tapout , tapout , tapout , tapout\n"
     ]
    }
   ],
   "source": [
    "sorted_scores = np.argsort(scores)\n",
    "\n",
    "n+=1\n",
    "\n",
    "print(cleaned_paras[sorted_scores[-n]])\n",
    "print()\n",
    "print(cleaned_paras[sorted_scores[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[174739 162688  67804 ..., 183260  98402 222899]\n",
      "cee - lo\n",
      "i . . . . have less than an hour\n",
      "ohhh . . . time will wait baby\n",
      "i . . . . have less than an hour\n",
      "ew - ohhh . . . . eww . . . . hmm . .\n",
      "i'm in the pursuit of my own personal power\n",
      "and i only have an hour\n"
     ]
    }
   ],
   "source": [
    "scores = [score_para(cp) for cp in cleaned_paras]\n",
    "\n",
    "print(cp.replace(\" [lb] \", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rare_ranks = dict([(x[0], i) for i, x in enumerate(word_counter.most_common())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233949"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('mediocre_rap_lyrics.txt', 'w') as f:\n",
    "    for i in sorted_scores[:len(sorted_scores) / 5]:\n",
    "        cp = cleaned_paras[i]\n",
    "        f.write(cp.replace(' [lb] ','\\n'))\n",
    "        f.write('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ans\n",
      "vevectlan\n",
      "spit rick  top\n",
      "wriss through the sbadd ax'll\n",
      "get tick port my sam"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-360409e672ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m        \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m    \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m    \u001b[0mnext_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m    \u001b[0mnext_char\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_char\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/Keras-1.1.0-py2.7.egg/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/Keras-1.1.0-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m         return self._predict_loop(f, ins,\n\u001b[1;32m-> 1192\u001b[1;33m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[0;32m   1193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/Keras-1.1.0-py2.7.egg/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/Keras-1.1.0-py2.7.egg/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[0mupdated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 382\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    383\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[0mmovers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_with_movers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 655\u001b[1;33m                            feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 723\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    724\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    728\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    710\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    711\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 712\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, diversity)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "    sys.stdout.write(next_char)\n",
    "    sys.stdout.flush()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "32554\n"
     ]
    }
   ],
   "source": [
    "word = 'humm'\n",
    "print word_counter[word]\n",
    "print rare_ranks[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17390"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_ranks['manhunt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops.rnn_cell import GRUCell, DropoutWrapper, MultiRNNCell, LSTMCell\n",
    "from tensorflow.python.ops.rnn import dynamic_rnn, rnn\n",
    "\n",
    "ops.reset_default_graph()\n",
    "try:\n",
    "    sess.close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "input_data = tf.placeholder(tf.int32, [BATCH_SIZE, NUM_STEPS])\n",
    "targets = tf.placeholder(tf.int32, [BATCH_SIZE, NUM_STEPS])\n",
    "\n",
    "NUM_LAYERS = 2\n",
    "LAYER_SIZE = 1024\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "initializer = tf.random_uniform_initializer(-0.05,0.05)\n",
    "with tf.variable_scope(\"model\", reuse=None, initializer=initializer):\n",
    "\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(LAYER_SIZE, forget_bias=0., state_is_tuple=True)\n",
    "    lstm_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_cell, output_keep_prob=keep_prob)\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * NUM_LAYERS, state_is_tuple=True)\n",
    "\n",
    "    initial_state = cell.zero_state(BATCH_SIZE, tf.float32)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\n",
    "          \"embedding\", [MAX_RANK + 3, 128], dtype=tf.float32)\n",
    "        inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    #inputs = tf.nn.dropout(inputs, keep_prob)\n",
    "\n",
    "    outputs = []\n",
    "    state = initial_state\n",
    "    with tf.variable_scope(\"RNN\"):\n",
    "        for time_step in range(NUM_STEPS):\n",
    "            if time_step > 0: \n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(inputs[:, time_step, :], state)\n",
    "            outputs.append(cell_output)\n",
    "\n",
    "    output = tf.reshape(tf.concat(1, outputs), [-1, LAYER_SIZE])\n",
    "    softmax_w = tf.get_variable(\n",
    "        \"softmax_w\", [LAYER_SIZE, MAX_RANK + 3], dtype=tf.float32)\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [MAX_RANK + 3], dtype=tf.float32)\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    output_unflattened = tf.reshape(logits, [-1, NUM_STEPS, MAX_RANK + 3])\n",
    "\n",
    "loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "    [logits],\n",
    "    [tf.reshape(targets, [-1])],\n",
    "    [tf.ones([BATCH_SIZE * NUM_STEPS], dtype=tf.float32)])\n",
    "cost = tf.reduce_sum(loss) / BATCH_SIZE\n",
    "final_state = state\n",
    "\n",
    "\n",
    "learning_rate =  tf.placeholder(tf.float32, shape=[])\n",
    "tvars = tf.trainable_variables()\n",
    "grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), MAX_GRAD_NORM)\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.05)\n",
    "train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297.98532"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_iter.next()\n",
    "sess.run(cost, feed_dict={input_data:x, targets:y, keep_prob:1.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_batch(iter_, lr, train=False):\n",
    "    x_, y_ = iter_.next()\n",
    "    \n",
    "    dp = 0.95 if train else 1.\n",
    "    #dp = 1.\n",
    "    \n",
    "    \n",
    "    fd = {input_data: x, targets: y, keep_prob : dp}\n",
    "    \n",
    "    if train:\n",
    "        fd[learning_rate] = lr\n",
    "        err, _  = sess.run([cost, train_op], feed_dict=fd)\n",
    "        \n",
    "    else:\n",
    "        err, = sess.run([cost], feed_dict=fd)\n",
    "    \n",
    "    return err\n",
    "\n",
    "def moving_average(a, n=16) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "errs =[]\n",
    "val_errs = []\n",
    "val_preds = []\n",
    "\n",
    "count = 0\n",
    "epoch = 0 \n",
    "\n",
    "LEARNING_RATE = 1.\n",
    "MAX_EPOCH = 6\n",
    "LR_DECAY = 0.8\n",
    "\n",
    "lr = LEARNING_RATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 931/931 [05:38<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STARTING EPOCH 1\n",
      "Model saved in file: rnn_model_2.ckpt"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 299/931 [01:47<03:43,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "STARTING EPOCH 2\n",
      "STOPPED BY KEYBOARD INTERRUPT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f14bd25ffd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "epoch_len = train_iter.epoch_length\n",
    "try:\n",
    "    while epoch < n_epochs:\n",
    "        print \"STARTING EPOCH %i\" %epoch\n",
    "        for index in tqdm(range(epoch_len)):\n",
    "            err = run_batch(train_iter, lr, train=True)\n",
    "            errs.append(err)\n",
    "            \n",
    "            if count % 2 == 0:\n",
    "                err = run_batch(val_iter, lr, train=False)\n",
    "                val_errs.append(err)\n",
    "                #val_preds.append(pred)\n",
    "            \n",
    "            count+=1 \n",
    "            \n",
    "        try:\n",
    "            save_path = saver.save(sess, \"rnn_model_%i.ckpt\" %(epoch + 1))\n",
    "            print(\"Model saved in file: %s\" % save_path)\n",
    "        except ValueError:\n",
    "            print \"couldn't save?\"\n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            a = moving_average(errs, n = 1000)\n",
    "            plt.plot(range(len(a)), a)\n",
    "            a = moving_average(val_errs, n = 1000 / 2)\n",
    "            plt.plot(range(0, len(a) * 2, 2), a)\n",
    "            plt.show()\n",
    "            \n",
    "        if epoch > MAX_EPOCH:\n",
    "            lr *= LR_DECAY\n",
    "                    \n",
    "except KeyboardInterrupt:\n",
    "    print \"STOPPED BY KEYBOARD INTERRUPT\"\n",
    "    a = moving_average(errs, n = 100)\n",
    "    plt.plot(range(len(a)), a)\n",
    "    plt.ylim((0, 0.1))\n",
    "    a = moving_average(val_errs, n = 100 / 2)\n",
    "    plt.plot(range(0, len(a) * 2, 2), a)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr /= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13e1755590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = moving_average(errs, n = 100) / BATCH_SIZE\n",
    "plt.plot(range(len(a)), a, color = 'blue')\n",
    "#plt.ylim((0, 0.1))\n",
    "a = moving_average(val_errs, n = 100 / 2) / BATCH_SIZE\n",
    "plt.plot(range(0, len(a) * 2, 2), a, color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(35840)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat(1, outputs).get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_, y_ = train_iter.next()\n",
    "    \n",
    "dp = 1.\n",
    "\n",
    "fd = {input_data: x_, targets: y_, keep_prob : dp}\n",
    "\n",
    "y_pred = sess.run(output_unflattened, feed_dict=fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"blue like [UNK] \\n cause i'm a [UNK] - millionaire who still using [UNK] \\n or country grammar we gon [UNK] in south atlanta \\n jesus was a [UNK] so we're proud about [UNK] them\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_ranks_reversed = dict([(v , k ) for k, v in rare_ranks.items()])\n",
    "def convert_to_words(vs):\n",
    "    out = []\n",
    "    for v in vs:\n",
    "        if v == MAX_RANK:\n",
    "            out.append('\\n')\n",
    "        elif v == MAX_RANK + 1:\n",
    "            out.append('\\n\\n')\n",
    "        elif v == MAX_RANK + 2:\n",
    "            out.append('[UNK]')\n",
    "        else:\n",
    "            out.append(rare_ranks_reversed[v])\n",
    "    return \" \".join(out)\n",
    "\n",
    "convert_to_words(x_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n",
      "0\n",
      "16\n",
      "338\n",
      "1580\n",
      "4535\n",
      "317\n",
      "1332\n",
      "990\n",
      "1332\n",
      "197\n",
      "585\n",
      "35\n",
      "0\n",
      "3850\n",
      "2936\n",
      "1089\n",
      "2826\n",
      "2258\n",
      "5002\n",
      "3315\n",
      "4168\n",
      "2666\n",
      "5000\n",
      "3499\n",
      "386\n",
      "534\n",
      "7\n",
      "2407\n",
      "3335\n",
      "3255\n",
      "1118\n",
      "0\n",
      "473\n",
      "3858\n"
     ]
    }
   ],
   "source": [
    "for i, y__ in enumerate(y_pred.argsort(axis=2)[0]):\n",
    "    print y__[y_[0, i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 5003)\n"
     ]
    }
   ],
   "source": [
    "print y_pred.argsort(axis=2)[0].shape #[:, y_[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argsort?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  15 5002 5000   48   11    4 5002   14 4525   85   95 2382 5002 5000   65\n",
      " 1317 4066   20  153 5002    8  554 2056 5000  807   43    4 5002   29  354\n",
      " 1508   89 5002   66 3038]\n",
      "[[ 18.13204575  20.38354301  12.16783047 ...,  21.36763763  13.08810806\n",
      "   18.6849041 ]\n",
      " [ 19.79428291  19.78723526  18.48643684 ...,  18.12086296  10.04360485\n",
      "   18.30866432]\n",
      " [ 25.82476616  23.99901962  21.24538612 ...,  25.73745346  17.43304062\n",
      "   23.38027763]\n",
      " ..., \n",
      " [ 23.79860306  19.86543465  19.30244827 ...,  22.19552612  16.2310009\n",
      "   21.6450634 ]\n",
      " [ 24.81319046  22.38414764  18.65096474 ...,  25.23698044  16.35422134\n",
      "   22.98103905]\n",
      " [ 23.46815491  18.80275726  19.22898293 ...,  23.38434219  13.37697983\n",
      "   21.40683746]]\n"
     ]
    }
   ],
   "source": [
    "print y_[0][:100]\n",
    "print y_pred[0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like [UNK] \n",
      " cause i'm a [UNK] - millionaire who still using [UNK] \n",
      " or country grammar we gon [UNK] in south atlanta \n",
      " jesus was a [UNK] so we're proud about [UNK] them hammers\n",
      "--------------------\n",
      "sayin , , i out the lot \n",
      " \n",
      " [UNK] from \n",
      " out sign my [UNK] mine kids promised [UNK] , sign , rode [UNK] back [UNK] my \n",
      " \n",
      " [UNK] \n",
      " , sign ,\n"
     ]
    }
   ],
   "source": [
    "print convert_to_words(y_[0])\n",
    "print \"-\" * 20\n",
    "print convert_to_words(y_pred.argmax(axis=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "axis(=2) out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-205b624f3e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/mike/envs/tensorflow/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m    972\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 974\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    975\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: axis(=2) out of bounds"
     ]
    }
   ],
   "source": [
    "np.argmax(y_pred, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  163 10000    11     1  3053    16    85  1252    11    28     1  1643\n",
      "  1272 10000  2727     1  1424   933    21   168   396 10002   210 10000\n",
      "  1234  1644     7 10002  6446 10000    85   199  2349    50     1]\n"
     ]
    }
   ],
   "source": [
    "print x_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"519'''\""
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"519'''\"\n",
    "re.sub(\"(^|\\s)'+\", \" \", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from stemming.porter2 import stem\n",
    "print stem('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('precis', 'ion')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_dict = {}\n",
    "\n",
    "def stem_word(w):\n",
    "    if w in stem_dict:\n",
    "        return stem_dict[w]\n",
    "    s = stem(w)\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for i, pair in enumerate(zip(s, w)):\n",
    "        c1, c2 = pair\n",
    "        \n",
    "        if c1 != c2:\n",
    "            return s, w[i:]\n",
    "    out = (s, w[i + 1:])    \n",
    "    stem_dict[w] = out\n",
    "    return out\n",
    "        \n",
    "stem_word(\"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({u'': 91040, u's': 20821, u'e': 16023, u'y': 7322, u'es': 6797, u'ed': 6510, u'ing': 5240, u'er': 2175, u'l': 1988, u'ic': 1294, u'ers': 1145, u'al': 1009, u'ion': 950, u'ly': 932, u'ate': 871, u'ys': 849, u'ous': 724, u'ation': 705, u'ness': 627, u'd': 562, u'able': 556, u'ated': 551, u'ings': 440, u'ions': 439, u'ics': 405, u'ent': 405, u'ive': 341, u'ating': 333, u'ity': 322, u'ize': 309, u'ical': 295, u'ations': 261, u'ant': 260, u'ized': 243, u'als': 239, u'ence': 238, u'ates': 237, u'ator': 220, u'ally': 209, u'ment': 204, u'ls': 201, u'ance': 198, u'ful': 197, u'ically': 183, u'ism': 161, u'ped': 159, u'ely': 156, u'ted': 131, u'ying': 127, u'ping': 117, u'ting': 116, u'ators': 109, u'izing': 101, u'ement': 99, u'ities': 97, u'ents': 95, u'ible': 95, u'ered': 92, u'led': 90, u'ments': 83, u'ged': 81, u'ling': 81, u'ously': 80, u'eds': 79, u'ants': 79, u'ging': 76, u'fully': 75, u'ional': 69, u'ably': 69, u'ative': 68, u'ively': 67, u'eness': 64, u'ning': 62, u'eable': 59, u'red': 59, u'eing': 58, u'med': 56, u'ler': 54, u'ently': 54, u'ned': 53, u'ming': 53, u'izer': 52, u'itys': 51, u'ication': 50, u'bed': 50, u'ives': 50, u'bing': 49, u'ingly': 47, u'ements': 47, u'edly': 46, u'ded': 46, u'ization': 43, u'or': 42, u'ering': 40, u'ring': 38, u'ately': 38, u'fed': 38, u'alize': 37, u'ality': 35, u'eer': 34, u'eous': 34, u'ational': 33, u'antly': 32, u'fing': 32, u'ency': 32, u'alism': 30, u'ding': 30, u'izes': 30, u'ies': 29, u'ences': 29, u'eful': 29, u'ances': 29, u'iveness': 28, u'lers': 28, u'lies': 28, u'ioned': 27, u'isms': 26, u'ors': 25, u'icals': 25, u'eal': 23, u'li': 22, u'alized': 22, u'ables': 22, u'ility': 22, u'icly': 22, u'icated': 21, u'yed': 21, u'nesses': 21, u'lys': 21, u'ousness': 21, u'pings': 20, u'itis': 20, u'fulness': 18, u'ancy': 18, u'eers': 17, u'ioning': 17, u'icate': 16, u'ented': 16, u'izers': 15, u'ibly': 15, u'lis': 15, u'ivity': 14, u'tings': 13, u'icity': 12, u'ications': 12, u'ionally': 12, u'ds': 11, u'fuls': 11, u'efully': 11, u'lation': 11, u'iced': 11, u'lable': 11, u'icness': 11, u'eli': 10, u'alizing': 10, u'ibles': 10, u'ibility': 10, u'alities': 10, u'lic': 10, u'nings': 9, u'encies': 9, u'eously': 8, u'mings': 8, u'erly': 8, u'atives': 8, u'ilities': 8, u'iti': 7, u'lment': 7, u'alization': 7, u'icating': 6, u'icing': 6, u'atively': 6, u'aling': 6, u'ability': 6, u'eering': 6, u'lations': 6, u'yingly': 6, u'eated': 6, u'izations': 5, u'late': 5, u'enting': 5, u'elis': 5, u'gings': 5, u'nessing': 5, u'erative': 5, u'icates': 5, u'lying': 5, u'lated': 5, u'alitys': 4, u'lence': 4, u'ancies': 4, u'dings': 4, u'alisms': 4, u'tingly': 4, u'ionals': 4, u'lous': 4, u'lness': 4, u'eered': 4, u'lical': 4, u'lity': 4, u'atings': 4, u'lize': 3, u'nessed': 3, u'ationals': 3, u'entness': 3, u'alness': 3, u'ivitys': 3, u'icities': 3, u'encys': 3, u'icator': 3, u'eating': 3, u'gedly': 3, u'ealing': 3, u'ionalism': 3, u'efulness': 3, u'eals': 3, u'aled': 3, u'eate': 3, u'ibilities': 3, u'bings': 3, u'alizes': 3, u'is': 3, u'lant': 3, u'lent': 3, u'anting': 3, u'i': 3, u'reds': 2, u'eism': 2, u'ilitys': 2, u'ealed': 2, u'entative': 2, u'eably': 2, u'ivities': 2, u'anted': 2, u'dly': 2, u'ningly': 2, u'atingly': 2, u'lator': 2, u'elies': 2, u'geds': 2, u'entatives': 2, u'lings': 2, u'mented': 2, u'lible': 2, u'erness': 2, u'lments': 2, u'allies': 2, u'lently': 2, u'lics': 2, u'allys': 2, u'lance': 2, u'mently': 2, u'eity': 2, u'lating': 2, u'erred': 2, u'eance': 1, u'abilities': 1, u'ateness': 1, u'ationalism': 1, u'menting': 1, u'alizer': 1, u'alizations': 1, u'alli': 1, u'eence': 1, u'ied': 1, u'neds': 1, u'eive': 1, u'ibilitys': 1, u'ibleness': 1, u'eator': 1, u'lism': 1, u'ateing': 1, u'ioningly': 1, u'enesses': 1, u'litys': 1, u'lously': 1, u'eement': 1, u'icitis': 1, u'lators': 1, u'ablies': 1, u'meds': 1, u'eant': 1, u'erlies': 1, u'fings': 1, u'ativeness': 1, u'eements': 1, u'ibling': 1, u'tedly': 1, u'lization': 1, u'ionings': 1, u'icality': 1, u'teds': 1, u'itiative': 1, u'lency': 1, u'allis': 1, u'ionly': 1, u'entful': 1, u'ateds': 1, u'ationally': 1, u'eic': 1, u'eations': 1, u'lized': 1, u'eics': 1, u'eings': 1, u'lably': 1, u'litis': 1, u'ancys': 1, u'yings': 1, u'ousing': 1, u'eables': 1, u'lates': 1, u'lingly': 1, u'efuls': 1, u'eances': 1, u'atored': 1, u'erlys': 1, u'lities': 1, u'icativeness': 1, u'oused': 1, u'lants': 1, u'antness': 1, u'lents': 1, u'encely': 1, u'icatedly': 1})"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = Counter()\n",
    "\n",
    "endings = set()\n",
    "\n",
    "for w in word_counter:\n",
    "    try:\n",
    "        s, t = stem_word(parse_text(w))\n",
    "    except:\n",
    "        print w\n",
    "        continue\n",
    "    if t.startswith(\"'\"):\n",
    "        print w\n",
    "        break\n",
    "    counter[t] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"breakdancin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'su'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_word(word):\n",
    "    stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216187/216187 [02:02<00:00, 1762.06it/s]\n"
     ]
    }
   ],
   "source": [
    "process_word_dict = {}\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "for text in tqdm(cleaned_paras):\n",
    "    txt = parse_text(text)\n",
    "    \n",
    "    for line in txt.split(\"\\n\"):\n",
    "        words = line.split()\n",
    "        for word in words:\n",
    "            if word in process_word_dict:\n",
    "                s, t = process_word_dict[word]\n",
    "            else:\n",
    "                s, t = stem_word(parse_text(word))\n",
    "                process_word_dict[word] = (s, t)\n",
    "            #s = stem(word)\n",
    "            word_counter[s] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = set([x[0] for x in word_counter.most_common(20000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904302715153888"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(sum([x[1] for x in word_counter.most_common(20000)])) / sum(word_counter.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289075\n",
      "289075\n"
     ]
    }
   ],
   "source": [
    "print len(word_counter)\n",
    "word_counter[\"askjdhfaadfabs\"]\n",
    "print len(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_words = set([x[0] for x in word_counter.most_common(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counter[\"pointer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bailin in'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def attempt_split(word):\n",
    "    out = None\n",
    "    max_score = 0\n",
    "    for i in range(1, len(word)):\n",
    "        w1 = word[:i]\n",
    "        w2 = word[i:]\n",
    "        if w1 in common_words and w2 in common_words:\n",
    "            score = word_counter[w1] + word_counter[w2]\n",
    "        \n",
    "            if score > max_score:\n",
    "                out = \"%s %s\" %(w1, w2)\n",
    "                \n",
    "    return out\n",
    "\n",
    "attempt_split(\"bailinin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dizzy 628\n",
      "bizzy 411\n",
      "swizz 314\n",
      "pizza 258\n",
      "blizzard 182\n",
      "krizz 164\n",
      "sizzle 141\n",
      "grizzly 130\n",
      "fizzy 112\n",
      "drizzy 110\n",
      "shizzle 110\n",
      "glizzy 105\n",
      "fizz 84\n",
      "sizzla 68\n",
      "gizzle 65\n",
      "fizzle 62\n",
      "nizzle 60\n",
      "drizzle 54\n",
      "sizzlin 54\n",
      "dizzle 53\n",
      "izzy 51\n",
      "sizzurp 50\n",
      "bizz 45\n",
      "twizzy 44\n",
      "jizzle 43\n",
      "thizzle 43\n",
      "sizzling 41\n",
      "grizzy 38\n",
      "wizzle 36\n",
      "thizz 36\n",
      "swizzz 34\n",
      "bizzle 34\n",
      "wizzy 32\n",
      "grizzle 31\n",
      "jizz 31\n",
      "dizzee 28\n",
      "swizzy 27\n",
      "hizzle 27\n",
      "izz 27\n",
      "izzo 26\n",
      "rizzle 26\n",
      "kizzy 25\n",
      "blizzards 24\n",
      "gizzy 22\n",
      "lizzy 22\n",
      "pizzle 21\n",
      "pizzas 21\n",
      "frizzy 21\n",
      "krizzle 20\n",
      "trizzy 20\n",
      "blizz 20\n",
      "slizzard 19\n",
      "sizzler 19\n",
      "pizzazz 19\n",
      "bizzare 18\n",
      "bizzack 18\n",
      "trizz 17\n",
      "rizzla 17\n",
      "lizzie 16\n",
      "sizzles 16\n",
      "glizzies 15\n",
      "wizzes 15\n",
      "rizzo 15\n",
      "tizzy 14\n",
      "stizzy 14\n",
      "rizzy 14\n",
      "gizzards 14\n",
      "pizzeria 13\n",
      "swizzle 13\n",
      "blizzy 12\n",
      "gizzard 12\n",
      "dizzie 12\n",
      "drizzlin 11\n",
      "gizzo 11\n",
      "dizzay 11\n",
      "izza 10\n",
      "kizzle 10\n",
      "mizzy 10\n",
      "izzle 10\n",
      "bizzalls 10\n",
      "hizzy 9\n",
      "dizzo 9\n",
      "dizziness 9\n",
      "izzay 9\n",
      "twizzie 8\n",
      "damizza 8\n",
      "grizzlies 8\n",
      "whizz 8\n",
      "sizz 8\n",
      "sizzerp 8\n",
      "mizzle 8\n",
      "drizzling 8\n",
      "grizz 8\n",
      "wizz 8\n",
      "fizzin 8\n",
      "wizzard 8\n",
      "chizz 8\n",
      "bizzay 8\n",
      "dizzier 7\n",
      "radizzo 7\n",
      "twizzler 7\n",
      "dizzel 7\n",
      "sizzlers 7\n",
      "sizzlin' 7\n",
      "kizz 7\n",
      "bizzall 7\n",
      "dizzert 7\n",
      "phizzle 7\n",
      "mizz 7\n",
      "fizzling 7\n",
      "cizzurb 7\n",
      "stizzle 7\n",
      "nizza 7\n",
      "nizzy 7\n",
      "plizzay 7\n",
      "pizzo 7\n",
      "shizzy 7\n",
      "shizzo 7\n",
      "swizzzle 7\n",
      "twizzlers 7\n",
      "strizzle 6\n",
      "sizzip 6\n",
      "hizzoes 6\n",
      "jizzy 6\n",
      "jizzal 6\n",
      "rizz 6\n",
      "fizzles 6\n",
      "chizzle 6\n",
      "skizzy 6\n",
      "showbizz 6\n",
      "trizzack 6\n",
      "thizzin 5\n",
      "jizzed 5\n",
      "yizzear 5\n",
      "trizzays 5\n",
      "crizzy 5\n",
      "slizzel 5\n",
      "kizzo 5\n",
      "nizzel 5\n",
      "izzah 5\n",
      "spizzot 5\n",
      "sizzay 5\n",
      "bizzar 5\n",
      "blizzock 5\n",
      "dizzogg 5\n",
      "whizzy 5\n",
      "hizzouse 5\n",
      "gizz 5\n",
      "fizzucked 5\n",
      "mizzo 5\n",
      "mizza 5\n",
      "frizz 5\n",
      "grizzill 5\n",
      "bizzo 5\n",
      "trizze 5\n",
      "wizzel 5\n",
      "wizzow 5\n",
      "izzon 5\n",
      "quizzes 5\n",
      "whizzed 5\n",
      "brizzles 5\n",
      "kizzies 4\n",
      "thizzo 4\n",
      "dizzyness 4\n",
      "nizzles 4\n",
      "quizzestion 4\n",
      "wizzerk 4\n",
      "mizzouth 4\n",
      "sizzlasie 4\n",
      "chizzy 4\n",
      "shizznit 4\n",
      "skizzied 4\n",
      "glizzock 4\n",
      "slizzered 4\n",
      "clizzub 4\n",
      "flizzy 4\n",
      "trizzle 4\n",
      "izzask 4\n",
      "pizzy 4\n",
      "kizzerp 4\n",
      "thizzat 4\n",
      "plizzy 4\n",
      "cizzle 4\n",
      "maybizzy 4\n",
      "dizzime 4\n",
      "lizzard 4\n",
      "hakizzle 4\n",
      "aftermizzath 4\n",
      "'sizzlean 4\n",
      "pizzit 4\n",
      "pizzerm 4\n",
      "lizzle 4\n",
      "rizzuto 4\n",
      "dizza 4\n",
      "gizzame 4\n",
      "drizzown 4\n",
      "dizz 4\n",
      "brizzle 4\n",
      "jizzum 4\n",
      "brizzy 4\n",
      "drizzled 4\n",
      "thizzack 4\n",
      "izzzup 4\n",
      "fizzur 4\n",
      "mizzel 4\n",
      "jizza 4\n",
      "pizzaz 4\n",
      "sizzlean 4\n",
      "whizzing 4\n",
      "whizzin 4\n",
      "quizzin 4\n",
      "trizzie 4\n",
      "shizz 4\n",
      "pizzerias 4\n",
      "bizzerk 4\n",
      "swizzerve 4\n",
      "shizzel 4\n",
      "dizzys 3\n",
      "hizzout 3\n",
      "lizzean 3\n",
      "grizzlin 3\n",
      "dizzoc 3\n",
      "chizzler 3\n",
      "hizzel 3\n",
      "bizzys 3\n",
      "schizzay 3\n",
      "wizzay 3\n",
      "wrizzla 3\n",
      "grizzats 3\n",
      "izze 3\n",
      "dizzles 3\n",
      "ahizzhead 3\n",
      "spizzle 3\n",
      "drizze 3\n",
      "gizze 3\n",
      "sizzyrup 3\n",
      "cizzay 3\n",
      "trizzin 3\n",
      "trizzay 3\n",
      "rizzos 3\n",
      "drizzay 3\n",
      "hizzard 3\n",
      "strizzay 3\n",
      "thurlthizzle 3\n",
      "dizzies 3\n",
      "grizzies 3\n",
      "crizzime 3\n",
      "snizzle 3\n",
      "frizzame 3\n",
      "lizza 3\n",
      "wizzles 3\n",
      "shizzat 3\n",
      "crizzo 3\n",
      "sizznay 3\n",
      "wizzit 3\n",
      "gurizzi 3\n",
      "bizzitch 3\n",
      "blizzood 3\n",
      "wizzord 3\n",
      "pizz 3\n",
      "pizzound 3\n",
      "dizzough 3\n",
      "dizznick 3\n",
      "wizzords 3\n",
      "hizzoe 3\n",
      "hizzot 3\n",
      "bizzed 3\n",
      "shizzit 3\n",
      "gizzank 3\n",
      "lizzock 3\n",
      "okizzay 3\n",
      "bizze 3\n",
      "jizzm 3\n",
      "pizzat 3\n",
      "grizzound 3\n",
      "sizzaid 3\n",
      "nizzay 3\n",
      "hizzurt 3\n",
      "tizzt 3\n",
      "brizzain 3\n",
      "kizzie 3\n",
      "nizzot 3\n",
      "bizzow 3\n",
      "sizzled 3\n",
      "jizzell 3\n",
      "rizzeal 3\n",
      "wrizzist 3\n",
      "dizzown 3\n",
      "whizzes 3\n",
      "lizzank 3\n",
      "flizzat 3\n",
      "tizzel 3\n",
      "rizzocks 3\n",
      "swizzll 3\n",
      "f'shizzle 2\n",
      "izzit 2\n",
      "swizzs 2\n",
      "blizzles 2\n",
      "rizzide 2\n",
      "sizzerved 2\n",
      "contizzest 2\n",
      "hizza 2\n",
      "drizzers 2\n",
      "shizzam 2\n",
      "dizzoo 2\n",
      "blizza 2\n",
      "mizzack 2\n",
      "hizzer 2\n",
      "izzitch 2\n",
      "grizzind 2\n",
      "tizzown 2\n",
      "sizzie 2\n",
      "shizzirl 2\n",
      "bizzz 2\n",
      "fizzor 2\n",
      "izzm 2\n",
      "izzl 2\n",
      "trizzies 2\n",
      "thizzles 2\n",
      "skizzirts 2\n",
      "prizzy 2\n",
      "shantizzle 2\n",
      "nizzide 2\n",
      "gizzie 2\n",
      "thizzangs 2\n",
      "slizzer 2\n",
      "jizzeans 2\n",
      "kurizzle 2\n",
      "chizzo 2\n",
      "fizzer 2\n",
      "dizzats 2\n",
      "grizzlet 2\n",
      "kizzi 2\n",
      "pizzounds 2\n",
      "rizzack 2\n",
      "swizzangin 2\n",
      "wizza 2\n",
      "fizza 2\n",
      "fizzo 2\n",
      "fizzi 2\n",
      "rizzight 2\n",
      "infizzy 2\n",
      "kizzys 2\n",
      "squizzy 2\n",
      "wizzur 2\n",
      "pizzearl 2\n",
      "fizzot 2\n",
      "jizzing 2\n",
      "wizzorld 2\n",
      "spizzy 2\n",
      "pizzzow 2\n",
      "nizzame 2\n",
      "boomdizzle 2\n",
      "strizzaw 2\n",
      "drizzo 2\n",
      "flizzo 2\n",
      "rizzler 2\n",
      "thizzness 2\n",
      "izzass 2\n",
      "dizzolars 2\n",
      "hizzerd 2\n",
      "pizzay 2\n",
      "dizzamn 2\n",
      "fo'rizzo 2\n",
      "dizznik 2\n",
      "pizzano 2\n",
      "schizzo 2\n",
      "pizzorno 2\n",
      "shizzi 2\n",
      "dizzyest 2\n",
      "wizzin 2\n",
      "wizzie 2\n",
      "pizzubs 2\n",
      "skizzle 2\n",
      "shacrizzy 2\n",
      "glizzys 2\n",
      "wizzack 2\n",
      "shizzop 2\n",
      "izzup 2\n",
      "dealizz 2\n",
      "quizzy 2\n",
      "splizzif 2\n",
      "swizzie 2\n",
      "bizzurk 2\n",
      "grandmizzle 2\n",
      "wizzork 2\n",
      "drizz 2\n",
      "jamizzle 2\n",
      "wrizzy 2\n",
      "bizzody 2\n",
      "dizzi 2\n",
      "dizze 2\n",
      "kizzay 2\n",
      "kizzat 2\n",
      "lizzone 2\n",
      "arizzound 2\n",
      "sizzed 2\n",
      "dizzip 2\n",
      "sizzouth 2\n",
      "hizzos 2\n",
      "twizzle 2\n",
      "stizz 2\n",
      "fizzine 2\n",
      "quizzing 2\n",
      "strizzeet 2\n",
      "brizzay 2\n",
      "grizzly' 2\n",
      "twizzys 2\n",
      "sizzelin 2\n",
      "dizzoes 2\n",
      "tizzide 2\n",
      "bizzird 2\n",
      "dizzick 2\n",
      "rizzucks 2\n",
      "stizzuck 2\n",
      "stizzar 2\n",
      "drizzles 2\n",
      "slizzled 2\n",
      "rizzump 2\n",
      "kintizzy 2\n",
      "confizzest 2\n",
      "bizzles 2\n",
      "bizzzzzzzz 2\n",
      "hizzigh 2\n",
      "fizzup 2\n",
      "bizzi 2\n",
      "bizza 2\n",
      "pizzissed 2\n",
      "chizznock 2\n",
      "'pizznac 2\n",
      "hystwhizzle 2\n",
      "y'knahmsizzlin 2\n",
      "mississizzle 2\n",
      "lizzys 2\n",
      "mizzarski 2\n",
      "dizzone 2\n",
      "frizzeak 2\n",
      "yayizzy 2\n",
      "sizzold 2\n",
      "grizzliest 2\n",
      "gizzat 2\n",
      "gizzay 2\n",
      "thizzery 2\n",
      "stizzicks 2\n",
      "grizzlie 2\n",
      "fizzlin 2\n",
      "remizzax 2\n",
      "rizzeals 2\n",
      "rizza 2\n",
      "bizzie 2\n",
      "dizzal 2\n",
      "twizzist 2\n",
      "lizzies 2\n",
      "ahizzead 2\n",
      "thrizzy 2\n",
      "swizz'll 2\n",
      "izzoo 2\n",
      "izzos 2\n",
      "lizzack 2\n",
      "sizzoft 2\n",
      "nizzo 2\n",
      "frizzin 2\n",
      "gizzurls 2\n",
      "lizzine 2\n",
      "jizzaws 2\n",
      "fizzive 2\n",
      "sizzer 2\n",
      "drizzae 2\n",
      "shtizzo 2\n",
      "yizzawnin 2\n",
      "blizzes 2\n",
      "sizzaw 2\n",
      "bizzat 2\n",
      "tizz 2\n",
      "tizzop 2\n",
      "hizzai 2\n",
      "izzer 2\n",
      "bizzity 2\n",
      "agizzle 2\n",
      "freewizzle 2\n",
      "nizzow 2\n",
      "shizzout 2\n",
      "pisapizza 2\n",
      "dizzell 2\n",
      "thizzlamic 2\n",
      "youjizz 2\n",
      "lizzay 2\n",
      "promizz 2\n",
      "shizzey 2\n",
      "fizzie 2\n",
      "frizzles 2\n",
      "sizzleen 2\n",
      "lizzook 2\n",
      "effizzect 2\n",
      "stizzep 1\n",
      "drizzlip 1\n",
      "gunplizzay 1\n",
      "dizzno 1\n",
      "bizzail 1\n",
      "frizzly 1\n",
      "frizzle 1\n",
      "chizzled 1\n",
      "chizzles 1\n",
      "sizzoldiers 1\n",
      "bizznitches 1\n",
      "tizzack 1\n",
      "gizzin 1\n",
      "scrufizzer 1\n",
      "mizzind 1\n",
      "mizzine 1\n",
      "kizznouch 1\n",
      "trizzae 1\n",
      "pizzimp 1\n",
      "blizzle 1\n",
      "jahizzle 1\n",
      "drizzop 1\n",
      "dizzy' 1\n",
      "crizzown 1\n",
      "mizzic 1\n",
      "mizzolas 1\n",
      "izzopear 1\n",
      "kunizzle 1\n",
      "scizzors 1\n",
      "minizzle 1\n",
      "mizzold 1\n",
      "fizzact 1\n",
      "thizzy 1\n",
      "thizzs 1\n",
      "rizzlers 1\n",
      "glizze 1\n",
      "swizz'd 1\n",
      "fo'shizzle 1\n",
      "ambanizza 1\n",
      "sizzurp'n 1\n",
      "brizzoke 1\n",
      "swizzzlefish 1\n",
      "drizzys 1\n",
      "blizzo 1\n",
      "clizzaim 1\n",
      "jizznoint 1\n",
      "hizzes 1\n",
      "wrizzeck 1\n",
      "pizznockets 1\n",
      "sizzin 1\n",
      "shizzirt 1\n",
      "swizzzles 1\n",
      "izzie 1\n",
      "quizzer 1\n",
      "quizzen 1\n",
      "quizzed 1\n",
      "crizzurb 1\n",
      "yizzap 1\n",
      "pizzack 1\n",
      "dizzneal 1\n",
      "tizzalkin 1\n",
      "wizzers 1\n",
      "wizzerd 1\n",
      "thizzlez 1\n",
      "dizzzy 1\n",
      "rizzoll 1\n",
      "fizzame 1\n",
      "blizzink 1\n",
      "fizzucks 1\n",
      "frizzends 1\n",
      "pittsbizzurgh 1\n",
      "knizz 1\n",
      "tizzeam 1\n",
      "fizzno 1\n",
      "dizzled 1\n",
      "snizz 1\n",
      "mizzery 1\n",
      "whizzite 1\n",
      "fizzed 1\n",
      "quizzically 1\n",
      "glizz 1\n",
      "grizzley 1\n",
      "swizzo 1\n",
      "jizzoc 1\n",
      "kizza 1\n",
      "pizzays 1\n",
      "pizzzay 1\n",
      "sizzy 1\n",
      "grizzlygristly 1\n",
      "spizz 1\n",
      "fizzuck 1\n",
      "whizzo 1\n",
      "cizzar 1\n",
      "smizzoke 1\n",
      "scrizzla 1\n",
      "fizzall 1\n",
      "nizzes 1\n",
      "fizzucka 1\n",
      "schnizzle 1\n",
      "mizzizzy 1\n",
      "yizzel 1\n",
      "clizzothes 1\n",
      "llizzac 1\n",
      "thizzlin 1\n",
      "infrarizzed 1\n",
      "stizzinock 1\n",
      "blizzent 1\n",
      "blizzardous 1\n",
      "rizzems 1\n",
      "thizzies 1\n",
      "slizzle 1\n",
      "fizzos 1\n",
      "tizznalkies 1\n",
      "shizznade 1\n",
      "pizzot 1\n",
      "thizzelle 1\n",
      "dizzling 1\n",
      "kizzack 1\n",
      "sizzeling 1\n",
      "rizzers 1\n",
      "spizza 1\n",
      "hizzihme 1\n",
      "wizzil 1\n",
      "strizzat 1\n",
      "lizzouder 1\n",
      "clizzown 1\n",
      "spizzop 1\n",
      "grizzyin 1\n",
      "gizzown 1\n",
      "sizzoe 1\n",
      "mizzall 1\n",
      "wizzink 1\n",
      "rizzles 1\n",
      "pizzini 1\n",
      "4fizzive 1\n",
      "mizzat 1\n",
      "mizzak 1\n",
      "cornbaunizzys 1\n",
      "pizznoot 1\n",
      "lizzi 1\n",
      "lizzo 1\n",
      "yizzi 1\n",
      "spprdekrizzah 1\n",
      "fa'shizzle 1\n",
      "dizznil 1\n",
      "tizzie 1\n",
      "drizzaws 1\n",
      "izzhog 1\n",
      "nizz 1\n",
      "izzerds 1\n",
      "grizzaz 1\n",
      "pizzimping 1\n",
      "cizzarn 1\n",
      "klizzy 1\n",
      "klizzo 1\n",
      "frizzes 1\n",
      "nizzie 1\n",
      "freewizzy 1\n",
      "thizzan 1\n",
      "izzzzzz 1\n",
      "drizzos 1\n",
      "trizzele 1\n",
      "frizzbee 1\n",
      "sizzar 1\n",
      "fizzled 1\n",
      "skizz 1\n",
      "shizznot 1\n",
      "gizzel 1\n",
      "gizzee 1\n",
      "fizzoe 1\n",
      "behizzind 1\n",
      "dizzlady 1\n",
      "subizzurb 1\n",
      "bizzile 1\n",
      "grizzling 1\n",
      "trizznuck 1\n",
      "kizzeel 1\n",
      "plizzle 1\n",
      "bizzoes 1\n",
      "shizzow 1\n",
      "hizzeel 1\n",
      "ltizzle 1\n",
      "grizzled 1\n",
      "shizzles 1\n",
      "izzum 1\n",
      "strizzapped 1\n",
      "fizzar 1\n",
      "pizznickin 1\n",
      "rizzoam 1\n",
      "hystwizzle 1\n",
      "whizzeel 1\n",
      "quizzz 1\n",
      "sizzaline 1\n",
      "fizzies 1\n",
      "vizzini 1\n",
      "jugglizzle 1\n",
      "seanizzle 1\n",
      "chrizz 1\n",
      "strizzled 1\n",
      "mizznission 1\n",
      "gurizzu 1\n",
      "grizzillz 1\n",
      "bizzzzzzzzz 1\n",
      "glizzery 1\n",
      "smizzle 1\n",
      "stizzo 1\n",
      "fizzil 1\n",
      "grizzetry 1\n",
      "sizzimp 1\n",
      "tizzosed 1\n",
      "drizzies 1\n",
      "bbbbuuuuuiiiiiiiizzzzzznnnnnnneeeeeezzzzzzz 1\n",
      "y'knahmsizzlayin 1\n",
      "bizzerth 1\n",
      "tizzart 1\n",
      "gizzoe 1\n",
      "biznizz 1\n",
      "tizzipsee 1\n",
      "dizzalls 1\n",
      "wizzies 1\n",
      "bizznoot 1\n",
      "chizzel 1\n",
      "trizzap 1\n",
      "spizzie 1\n",
      "lizzy'll 1\n",
      "dizzon't 1\n",
      "blizznuts 1\n",
      "jizzys 1\n",
      "rizzeign 1\n",
      "bizznottle 1\n",
      "lizzette 1\n",
      "pizzaman 1\n",
      "cizzo 1\n",
      "sizziline 1\n",
      "blizza' 1\n",
      "nizzight 1\n",
      "frizzench 1\n",
      "thizzlas 1\n",
      "scrizzach 1\n",
      "scientizzic 1\n",
      "shizzink 1\n",
      "brizzoads 1\n",
      "staybizzy 1\n",
      "mizzu 1\n",
      "lizzards 1\n",
      "prizzops 1\n",
      "wizzacks 1\n",
      "bizznews 1\n",
      "tizzime 1\n",
      "mizzym 1\n",
      "hizzow 1\n",
      "frizznied 1\n",
      "fizzives 1\n",
      "swizzyin 1\n",
      "fizzat 1\n",
      "wizzife 1\n",
      "hykizzle 1\n",
      "brizzas 1\n",
      "bizzies 1\n",
      "lizzives 1\n",
      "gizzardheads 1\n",
      "crizzome 1\n",
      "blizzack 1\n",
      "hizzbut 1\n",
      "ridejizzal 1\n",
      "shizzie 1\n",
      "rizzink 1\n",
      "dizzoe 1\n",
      "spizznot 1\n",
      "rizzap 1\n",
      "glizzly 1\n",
      "mizzou 1\n",
      "mizzos 1\n",
      "izzzz 1\n",
      "jizzinock 1\n",
      "hizz 1\n",
      "bizzin 1\n",
      "crizzin 1\n",
      "dizzice 1\n",
      "gizzing 1\n",
      "saukratizzy 1\n",
      "strizzeets 1\n",
      "shizzort 1\n",
      "sizzack 1\n",
      "fizzench 1\n",
      "crizzossed 1\n",
      "izzims 1\n",
      "strizzy 1\n",
      "kizzart 1\n",
      "mizzmillimeter 1\n",
      "frizzauds 1\n",
      "blizznut 1\n",
      "flizz 1\n",
      "izzerb 1\n",
      "drizzeam 1\n",
      "trizzo 1\n",
      "izzinine 1\n",
      "blizzies 1\n",
      "mizzell 1\n",
      "jizzi 1\n",
      "frizziness 1\n",
      "shizzayhow 1\n",
      "rizzas 1\n",
      "chizznocklate 1\n",
      "hizzzle 1\n",
      "pizzae 1\n",
      "brizzeak 1\n",
      "sizzors 1\n",
      "sizzerhand 1\n",
      "brizza 1\n",
      "hypnotizzo 1\n",
      "wizzat 1\n",
      "gizzantic 1\n",
      "thizzel 1\n",
      "lizzocs 1\n",
      "lizzife 1\n",
      "smizzo 1\n",
      "thizzerd 1\n",
      "bizzurb 1\n",
      "rizzapper 1\n",
      "tizzo 1\n",
      "crizzack 1\n",
      "wizzed 1\n",
      "pizzaro 1\n",
      "sizzel 1\n",
      "bizzirds 1\n",
      "tizzongue 1\n",
      "blizzie 1\n",
      "twizze 1\n",
      "chizzeck 1\n",
      "k'jizzo 1\n",
      "chizzops 1\n",
      "clizzaire 1\n",
      "grizzeel 1\n",
      "rizzi 1\n",
      "strizzong 1\n",
      "chizzoke 1\n",
      "dizzat 1\n",
      "thizzin' 1\n",
      "'izzed 1\n",
      "izzurp 1\n",
      "phizznilly 1\n",
      "drizzze 1\n",
      "blizzaards 1\n",
      "lizz 1\n",
      "wizzos 1\n",
      "wizzot 1\n",
      "sizzers 1\n",
      "fizzool 1\n",
      "caribizzle 1\n",
      "izzles 1\n",
      "bizzary 1\n",
      "mizzalls 1\n",
      "shizzerl 1\n",
      "drizzive 1\n",
      "shizzerts 1\n",
      "prizzmatic 1\n",
      "mizzorn 1\n",
      "izzerth 1\n",
      "rizzep 1\n",
      "bizzerd 1\n",
      "bizzerp 1\n",
      "gfizz 1\n",
      "dizzicko 1\n",
      "dizzicks 1\n",
      "producshizzle 1\n",
      "rizzys 1\n",
      "y'knahmshizzlayin 1\n",
      "trizzain 1\n",
      "twizzeline 1\n",
      "wizzing 1\n",
      "blizzed 1\n",
      "kizzel 1\n",
      "mizzake 1\n",
      "shizza 1\n",
      "izzeye 1\n",
      "flizzow 1\n",
      "bizzynizm 1\n",
      "wizzys 1\n",
      "pizzurp 1\n",
      "spizzeaks 1\n",
      "dizziest 1\n",
      "izzi 1\n",
      "chizzay 1\n",
      "dizzying 1\n",
      "hizzeard 1\n",
      "pizzlin 1\n",
      "quizzin' 1\n",
      "stizzop 1\n",
      "grizz' 1\n",
      "prizzice 1\n",
      "jizzail 1\n",
      "tizznelevision 1\n",
      "skizzo 1\n",
      "skizza 1\n",
      "hizzayyo 1\n",
      "wizzown 1\n",
      "thizzlin' 1\n",
      "cizz 1\n",
      "fizzeel 1\n",
      "snizza 1\n",
      "clizzy 1\n",
      "blizzow 1\n",
      "explizzit 1\n",
      "aquafizzy 1\n",
      "lizzaw 1\n",
      "lizzap 1\n",
      "clizzack 1\n",
      "frizzled 1\n",
      "crizzawl 1\n",
      "cizzil 1\n",
      "exsquizzy 1\n",
      "rizzes 1\n",
      "rizzel 1\n",
      "televizzle 1\n",
      "bizzench 1\n",
      "splizzy 1\n",
      "fizzdom 1\n"
     ]
    }
   ],
   "source": [
    "for word, count in word_counter.most_common():\n",
    "    if \"izz\" in word:\n",
    "        print word, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216187/216187 [01:09<00:00, 3090.24it/s]\n"
     ]
    }
   ],
   "source": [
    "indices = np.random.permutation(range(len(cleaned_paras)))\n",
    "\n",
    "stemmed_out = open(\"cleaned_rap.txt\", \"w\")\n",
    "\n",
    "for i in tqdm(indices):\n",
    "    text = cleaned_paras[i]\n",
    "    txt = parse_text(text)\n",
    "    \n",
    "    lines = txt.split(\"\\n\")\n",
    "    start_idx = 0\n",
    "    \n",
    "    if \"[\" in lines[0] and \"]\" in lines[0] or len(lines) < 20:\n",
    "        start_idx = 1\n",
    "    \n",
    "    for line in lines[start_idx:]:\n",
    "        stemmed_out.write(line + \"\\n\")\n",
    "#         split = line.split()\n",
    "#         if len(split) == 1:\n",
    "#             continue\n",
    "#         to_file = []\n",
    "#         for w in split:\n",
    "#             s, r = stem_word(w)\n",
    "#             if s in common_words:\n",
    "#                 to_file.append(s)\n",
    "#             else:\n",
    "#                 to_file.append(\"[UNK]\")\n",
    "#             if r!= \"\":\n",
    "#                 to_file.append(\"[%s]\"%r)\n",
    "#         s_out = \" \".join(to_file) + \"\\n\"\n",
    "#         stemmed_out.write(s_out)\n",
    "    stemmed_out.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216187/216187 [01:11<00:00, 3027.10it/s]\n"
     ]
    }
   ],
   "source": [
    "line_lengths = []\n",
    "\n",
    "for i in tqdm(indices):\n",
    "    text = cleaned_paras[i]\n",
    "    txt = parse_text(text)\n",
    "    \n",
    "    lines = txt.split(\"\\n\")\n",
    "    start_idx = 0\n",
    "    \n",
    "    if \"[\" in lines[0] and \"]\" in lines[0] or len(lines) < 20:\n",
    "        start_idx = 1\n",
    "    \n",
    "    for line in lines[start_idx:]:\n",
    "        line_lengths.append(len(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.429201322323053"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(line_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
